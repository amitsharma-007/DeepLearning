{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.There is a trained model we want to re-train some of the layers on our custom datased.\n",
    "## 2.Training a pretrained model completely on custom dataset is transfer learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Large and Different Dataset >> Fine-Tuning\n",
    "2. Large and Similar Dataset >> Fine-Tuning\n",
    "3. Small and Different Dataset >> Fine-Tuning\n",
    "4. Small and Similar Dataset >> Transfer-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src='https://www.topbots.com/wp-content/uploads/2019/12/cover_transfer_learning_1600px_web-1280x640.jpg', width=600, height=300>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src='https://www.topbots.com/wp-content/uploads/2019/12/cover_transfer_learning_1600px_web-1280x640.jpg', width=600, height=300>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!wget --no-check-certificate \\\n",
    "    https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
    "    -O /tmp/cats_and_dogs_filtered.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  0% [                                                                        ]        0 / 68606236\r",
      "  0% [                                                                        ]     8192 / 68606236\r",
      "  0% [                                                                        ]    16384 / 68606236\r",
      "  0% [                                                                        ]    24576 / 68606236\r",
      "  0% [                                                                        ]    32768 / 68606236\r",
      "  0% [                                                                        ]    40960 / 68606236\r",
      "  0% [                                                                        ]    49152 / 68606236\r",
      "  0% [                                                                        ]    57344 / 68606236\r",
      "  0% [                                                                        ]    65536 / 68606236\r",
      "  0% [                                                                        ]    73728 / 68606236\r",
      "  0% [                                                                        ]    81920 / 68606236\r",
      "  0% [                                                                        ]    90112 / 68606236\r",
      "  0% [                                                                        ]    98304 / 68606236\r",
      "  0% [                                                                        ]   106496 / 68606236\r",
      "  0% [                                                                        ]   114688 / 68606236\r",
      "  0% [                                                                        ]   122880 / 68606236\r",
      "  0% [                                                                        ]   131072 / 68606236\r",
      "  0% [                                                                        ]   139264 / 68606236\r",
      "  0% [                                                                        ]   147456 / 68606236\r",
      "  0% [                                                                        ]   155648 / 68606236\r",
      "  0% [                                                                        ]   163840 / 68606236\r",
      "  0% [                                                                        ]   172032 / 68606236\r",
      "  0% [                                                                        ]   180224 / 68606236\r",
      "  0% [                                                                        ]   188416 / 68606236\r",
      "  0% [                                                                        ]   196608 / 68606236\r",
      "  0% [                                                                        ]   204800 / 68606236\r",
      "  0% [                                                                        ]   212992 / 68606236\r",
      "  0% [                                                                        ]   221184 / 68606236\r",
      "  0% [                                                                        ]   229376 / 68606236\r",
      "  0% [                                                                        ]   237568 / 68606236\r",
      "  0% [                                                                        ]   245760 / 68606236\r",
      "  0% [                                                                        ]   253952 / 68606236\r",
      "  0% [                                                                        ]   262144 / 68606236\r",
      "  0% [                                                                        ]   270336 / 68606236\r",
      "  0% [                                                                        ]   278528 / 68606236\r",
      "  0% [                                                                        ]   286720 / 68606236\r",
      "  0% [                                                                        ]   294912 / 68606236\r",
      "  0% [                                                                        ]   303104 / 68606236\r",
      "  0% [                                                                        ]   311296 / 68606236\r",
      "  0% [                                                                        ]   319488 / 68606236\r",
      "  0% [                                                                        ]   327680 / 68606236\r",
      "  0% [                                                                        ]   335872 / 68606236\r",
      "  0% [                                                                        ]   344064 / 68606236\r",
      "  0% [                                                                        ]   352256 / 68606236\r",
      "  0% [                                                                        ]   360448 / 68606236\r",
      "  0% [                                                                        ]   368640 / 68606236\r",
      "  0% [                                                                        ]   376832 / 68606236\r",
      "  0% [                                                                        ]   385024 / 68606236\r",
      "  0% [                                                                        ]   393216 / 68606236\r",
      "  0% [                                                                        ]   401408 / 68606236\r",
      "  0% [                                                                        ]   409600 / 68606236\r",
      "  0% [                                                                        ]   417792 / 68606236\r",
      "  0% [                                                                        ]   425984 / 68606236\r",
      "  0% [                                                                        ]   434176 / 68606236\r",
      "  0% [                                                                        ]   442368 / 68606236\r",
      "  0% [                                                                        ]   450560 / 68606236\r",
      "  0% [                                                                        ]   458752 / 68606236\r",
      "  0% [                                                                        ]   466944 / 68606236\r",
      "  0% [                                                                        ]   475136 / 68606236\r",
      "  0% [                                                                        ]   483328 / 68606236\r",
      "  0% [                                                                        ]   491520 / 68606236\r",
      "  0% [                                                                        ]   499712 / 68606236\r",
      "  0% [                                                                        ]   507904 / 68606236\r",
      "  0% [                                                                        ]   516096 / 68606236\r",
      "  0% [                                                                        ]   524288 / 68606236\r",
      "  0% [                                                                        ]   532480 / 68606236\r",
      "  0% [                                                                        ]   540672 / 68606236\r",
      "  0% [                                                                        ]   548864 / 68606236\r",
      "  0% [                                                                        ]   557056 / 68606236\r",
      "  0% [                                                                        ]   565248 / 68606236\r",
      "  0% [                                                                        ]   573440 / 68606236\r",
      "  0% [                                                                        ]   581632 / 68606236\r",
      "  0% [                                                                        ]   589824 / 68606236\r",
      "  0% [                                                                        ]   598016 / 68606236\r",
      "  0% [                                                                        ]   606208 / 68606236\r",
      "  0% [                                                                        ]   614400 / 68606236\r",
      "  0% [                                                                        ]   622592 / 68606236\r",
      "  0% [                                                                        ]   630784 / 68606236\r",
      "  0% [                                                                        ]   638976 / 68606236\r",
      "  0% [                                                                        ]   647168 / 68606236\r",
      "  0% [                                                                        ]   655360 / 68606236\r",
      "  0% [                                                                        ]   663552 / 68606236\r",
      "  0% [                                                                        ]   671744 / 68606236\r",
      "  0% [                                                                        ]   679936 / 68606236\r",
      "  1% [                                                                        ]   688128 / 68606236\r",
      "  1% [                                                                        ]   696320 / 68606236\r",
      "  1% [                                                                        ]   704512 / 68606236\r",
      "  1% [                                                                        ]   712704 / 68606236\r",
      "  1% [                                                                        ]   720896 / 68606236\r",
      "  1% [                                                                        ]   729088 / 68606236\r",
      "  1% [                                                                        ]   737280 / 68606236\r",
      "  1% [                                                                        ]   745472 / 68606236\r",
      "  1% [                                                                        ]   753664 / 68606236\r",
      "  1% [                                                                        ]   761856 / 68606236\r",
      "  1% [                                                                        ]   770048 / 68606236\r",
      "  1% [                                                                        ]   778240 / 68606236\r",
      "  1% [                                                                        ]   786432 / 68606236\r",
      "  1% [                                                                        ]   794624 / 68606236\r",
      "  1% [                                                                        ]   802816 / 68606236\r",
      "  1% [                                                                        ]   811008 / 68606236\r",
      "  1% [                                                                        ]   819200 / 68606236\r",
      "  1% [                                                                        ]   827392 / 68606236\r",
      "  1% [                                                                        ]   835584 / 68606236\r",
      "  1% [                                                                        ]   843776 / 68606236\r",
      "  1% [                                                                        ]   851968 / 68606236\r",
      "  1% [                                                                        ]   860160 / 68606236\r",
      "  1% [                                                                        ]   868352 / 68606236\r",
      "  1% [                                                                        ]   876544 / 68606236\r",
      "  1% [                                                                        ]   884736 / 68606236\r",
      "  1% [                                                                        ]   892928 / 68606236\r",
      "  1% [                                                                        ]   901120 / 68606236\r",
      "  1% [                                                                        ]   909312 / 68606236\r",
      "  1% [                                                                        ]   917504 / 68606236\r",
      "  1% [                                                                        ]   925696 / 68606236\r",
      "  1% [                                                                        ]   933888 / 68606236\r",
      "  1% [                                                                        ]   942080 / 68606236\r",
      "  1% [                                                                        ]   950272 / 68606236\r",
      "  1% [.                                                                       ]   958464 / 68606236\r",
      "  1% [.                                                                       ]   966656 / 68606236\r",
      "  1% [.                                                                       ]   974848 / 68606236"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% [........................................................................] 68606236 / 68606236"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./cats_and_dogs_filtered.zip'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wget\n",
    "wget.download('https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip', './cats_and_dogs_filtered.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-gpu==2.1.0 in c:\\users\\eds16\\anaconda3\\lib\\site-packages (2.1.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\eds16\\anaconda3\\lib\\site-packages (from tensorflow-gpu==2.1.0) (3.1.0)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in c:\\users\\eds16\\anaconda3\\lib\\site-packages (from tensorflow-gpu==2.1.0) (0.33.6)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in c:\\users\\eds16\\anaconda3\\lib\\site-packages (from tensorflow-gpu==2.1.0) (0.1.8)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\eds16\\anaconda3\\lib\\site-packages (from tensorflow-gpu==2.1.0) (1.1.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in c:\\users\\eds16\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow-gpu==2.1.0) (1.11.2)\n",
      "Requirement already satisfied: astor>=0.6.0 in c:\\users\\eds16\\anaconda3\\lib\\site-packages (from tensorflow-gpu==2.1.0) (0.8.1)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in c:\\users\\eds16\\anaconda3\\lib\\site-packages (from tensorflow-gpu==2.1.0) (3.11.2)\n",
      "Requirement already satisfied: tensorflow-gpu-estimator<2.2.0,>=2.1.0rc0 in c:\\users\\eds16\\anaconda3\\lib\\site-packages (from tensorflow-gpu==2.1.0) (2.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\eds16\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow-gpu==2.1.0) (1.14.0)\n",
      "Requirement already satisfied: gast==0.2.2 in c:\\users\\eds16\\anaconda3\\lib\\site-packages (from tensorflow-gpu==2.1.0) (0.2.2)\n",
      "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in c:\\users\\eds16\\anaconda3\\lib\\site-packages (from tensorflow-gpu==2.1.0) (1.4.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in c:\\users\\eds16\\anaconda3\\lib\\site-packages (from tensorflow-gpu==2.1.0) (1.1.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in c:\\users\\eds16\\anaconda3\\lib\\site-packages (from tensorflow-gpu==2.1.0) (1.26.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in c:\\users\\eds16\\anaconda3\\lib\\site-packages (from tensorflow-gpu==2.1.0) (0.9.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in c:\\users\\eds16\\anaconda3\\lib\\site-packages (from tensorflow-gpu==2.1.0) (1.0.8)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in c:\\users\\eds16\\anaconda3\\lib\\site-packages (from tensorflow-gpu==2.1.0) (1.16.5)\n",
      "Requirement already satisfied: tensorboard<2.2.0,>=2.1.0 in c:\\users\\eds16\\anaconda3\\lib\\site-packages (from tensorflow-gpu==2.1.0) (2.1.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\eds16\\anaconda3\\lib\\site-packages (from protobuf>=3.8.0->tensorflow-gpu==2.1.0) (41.4.0)\n",
      "Requirement already satisfied: h5py in c:\\users\\eds16\\anaconda3\\lib\\site-packages (from keras-applications>=1.0.8->tensorflow-gpu==2.1.0) (2.9.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\eds16\\anaconda3\\lib\\site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (0.16.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\eds16\\anaconda3\\lib\\site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (2.22.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\eds16\\anaconda3\\lib\\site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (3.1.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\eds16\\anaconda3\\lib\\site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (0.4.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\eds16\\anaconda3\\lib\\site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (1.10.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\eds16\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (1.24.2)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\eds16\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\eds16\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (2019.9.11)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\eds16\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\eds16\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (1.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\eds16\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (0.2.7)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\eds16\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (4.0.0)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in c:\\users\\eds16\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (4.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\eds16\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (3.1.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\eds16\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (0.4.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-gpu==2.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm_notebook\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_keras_api_names',\n",
       " '_keras_api_names_v1',\n",
       " 'apply_transform',\n",
       " 'fit',\n",
       " 'flow',\n",
       " 'flow_from_dataframe',\n",
       " 'flow_from_directory',\n",
       " 'get_random_transform',\n",
       " 'random_transform',\n",
       " 'standardize']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(ImageDataGenerator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_extract_object = zipfile.ZipFile(file='./cats_and_dogs_filtered.zip', mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_extract_object.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_extract_object.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./cats_and_dogs_filtered/train\n",
      "./cats_and_dogs_filtered/validation\n"
     ]
    }
   ],
   "source": [
    "dataset_dir = './cats_and_dogs_filtered/'\n",
    "train_dir = os.path.join(dataset_dir, 'train')\n",
    "validation_dir = os.path.join(dataset_dir, 'validation')\n",
    "print(train_dir)\n",
    "print(validation_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SHAPE = (128, 128, 3)\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape = IMAGE_SHAPE, include_top=False, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mobilenetv2_1.00_128\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 128, 128, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Conv1_pad (ZeroPadding2D)       (None, 129, 129, 3)  0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Conv1 (Conv2D)                  (None, 64, 64, 32)   864         Conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_Conv1 (BatchNormalization)   (None, 64, 64, 32)   128         Conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Conv1_relu (ReLU)               (None, 64, 64, 32)   0           bn_Conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise (Depthw (None, 64, 64, 32)   288         Conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise_BN (Bat (None, 64, 64, 32)   128         expanded_conv_depthwise[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise_relu (R (None, 64, 64, 32)   0           expanded_conv_depthwise_BN[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_project (Conv2D)  (None, 64, 64, 16)   512         expanded_conv_depthwise_relu[0][0\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_project_BN (Batch (None, 64, 64, 16)   64          expanded_conv_project[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand (Conv2D)         (None, 64, 64, 96)   1536        expanded_conv_project_BN[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand_BN (BatchNormali (None, 64, 64, 96)   384         block_1_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand_relu (ReLU)      (None, 64, 64, 96)   0           block_1_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_1_pad (ZeroPadding2D)     (None, 65, 65, 96)   0           block_1_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise (DepthwiseCon (None, 32, 32, 96)   864         block_1_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise_BN (BatchNorm (None, 32, 32, 96)   384         block_1_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise_relu (ReLU)   (None, 32, 32, 96)   0           block_1_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_1_project (Conv2D)        (None, 32, 32, 24)   2304        block_1_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_1_project_BN (BatchNormal (None, 32, 32, 24)   96          block_1_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand (Conv2D)         (None, 32, 32, 144)  3456        block_1_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand_BN (BatchNormali (None, 32, 32, 144)  576         block_2_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand_relu (ReLU)      (None, 32, 32, 144)  0           block_2_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise (DepthwiseCon (None, 32, 32, 144)  1296        block_2_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise_BN (BatchNorm (None, 32, 32, 144)  576         block_2_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise_relu (ReLU)   (None, 32, 32, 144)  0           block_2_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_2_project (Conv2D)        (None, 32, 32, 24)   3456        block_2_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_2_project_BN (BatchNormal (None, 32, 32, 24)   96          block_2_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2_add (Add)               (None, 32, 32, 24)   0           block_1_project_BN[0][0]         \n",
      "                                                                 block_2_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand (Conv2D)         (None, 32, 32, 144)  3456        block_2_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand_BN (BatchNormali (None, 32, 32, 144)  576         block_3_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand_relu (ReLU)      (None, 32, 32, 144)  0           block_3_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_3_pad (ZeroPadding2D)     (None, 33, 33, 144)  0           block_3_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise (DepthwiseCon (None, 16, 16, 144)  1296        block_3_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise_BN (BatchNorm (None, 16, 16, 144)  576         block_3_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise_relu (ReLU)   (None, 16, 16, 144)  0           block_3_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_3_project (Conv2D)        (None, 16, 16, 32)   4608        block_3_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_3_project_BN (BatchNormal (None, 16, 16, 32)   128         block_3_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand (Conv2D)         (None, 16, 16, 192)  6144        block_3_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand_BN (BatchNormali (None, 16, 16, 192)  768         block_4_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block_4_expand_relu (ReLU)      (None, 16, 16, 192)  0           block_4_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise (DepthwiseCon (None, 16, 16, 192)  1728        block_4_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise_BN (BatchNorm (None, 16, 16, 192)  768         block_4_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise_relu (ReLU)   (None, 16, 16, 192)  0           block_4_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_4_project (Conv2D)        (None, 16, 16, 32)   6144        block_4_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_4_project_BN (BatchNormal (None, 16, 16, 32)   128         block_4_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4_add (Add)               (None, 16, 16, 32)   0           block_3_project_BN[0][0]         \n",
      "                                                                 block_4_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand (Conv2D)         (None, 16, 16, 192)  6144        block_4_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand_BN (BatchNormali (None, 16, 16, 192)  768         block_5_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand_relu (ReLU)      (None, 16, 16, 192)  0           block_5_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise (DepthwiseCon (None, 16, 16, 192)  1728        block_5_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise_BN (BatchNorm (None, 16, 16, 192)  768         block_5_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise_relu (ReLU)   (None, 16, 16, 192)  0           block_5_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_5_project (Conv2D)        (None, 16, 16, 32)   6144        block_5_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_5_project_BN (BatchNormal (None, 16, 16, 32)   128         block_5_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_5_add (Add)               (None, 16, 16, 32)   0           block_4_add[0][0]                \n",
      "                                                                 block_5_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand (Conv2D)         (None, 16, 16, 192)  6144        block_5_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand_BN (BatchNormali (None, 16, 16, 192)  768         block_6_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand_relu (ReLU)      (None, 16, 16, 192)  0           block_6_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_6_pad (ZeroPadding2D)     (None, 17, 17, 192)  0           block_6_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise (DepthwiseCon (None, 8, 8, 192)    1728        block_6_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise_BN (BatchNorm (None, 8, 8, 192)    768         block_6_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise_relu (ReLU)   (None, 8, 8, 192)    0           block_6_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_6_project (Conv2D)        (None, 8, 8, 64)     12288       block_6_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_6_project_BN (BatchNormal (None, 8, 8, 64)     256         block_6_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand (Conv2D)         (None, 8, 8, 384)    24576       block_6_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand_BN (BatchNormali (None, 8, 8, 384)    1536        block_7_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand_relu (ReLU)      (None, 8, 8, 384)    0           block_7_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise (DepthwiseCon (None, 8, 8, 384)    3456        block_7_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise_BN (BatchNorm (None, 8, 8, 384)    1536        block_7_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise_relu (ReLU)   (None, 8, 8, 384)    0           block_7_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_7_project (Conv2D)        (None, 8, 8, 64)     24576       block_7_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_7_project_BN (BatchNormal (None, 8, 8, 64)     256         block_7_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_7_add (Add)               (None, 8, 8, 64)     0           block_6_project_BN[0][0]         \n",
      "                                                                 block_7_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand (Conv2D)         (None, 8, 8, 384)    24576       block_7_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand_BN (BatchNormali (None, 8, 8, 384)    1536        block_8_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand_relu (ReLU)      (None, 8, 8, 384)    0           block_8_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise (DepthwiseCon (None, 8, 8, 384)    3456        block_8_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise_BN (BatchNorm (None, 8, 8, 384)    1536        block_8_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise_relu (ReLU)   (None, 8, 8, 384)    0           block_8_depthwise_BN[0][0]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "block_8_project (Conv2D)        (None, 8, 8, 64)     24576       block_8_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_8_project_BN (BatchNormal (None, 8, 8, 64)     256         block_8_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_8_add (Add)               (None, 8, 8, 64)     0           block_7_add[0][0]                \n",
      "                                                                 block_8_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand (Conv2D)         (None, 8, 8, 384)    24576       block_8_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand_BN (BatchNormali (None, 8, 8, 384)    1536        block_9_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand_relu (ReLU)      (None, 8, 8, 384)    0           block_9_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise (DepthwiseCon (None, 8, 8, 384)    3456        block_9_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise_BN (BatchNorm (None, 8, 8, 384)    1536        block_9_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise_relu (ReLU)   (None, 8, 8, 384)    0           block_9_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_9_project (Conv2D)        (None, 8, 8, 64)     24576       block_9_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_9_project_BN (BatchNormal (None, 8, 8, 64)     256         block_9_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_9_add (Add)               (None, 8, 8, 64)     0           block_8_add[0][0]                \n",
      "                                                                 block_9_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand (Conv2D)        (None, 8, 8, 384)    24576       block_9_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand_BN (BatchNormal (None, 8, 8, 384)    1536        block_10_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand_relu (ReLU)     (None, 8, 8, 384)    0           block_10_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise (DepthwiseCo (None, 8, 8, 384)    3456        block_10_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise_BN (BatchNor (None, 8, 8, 384)    1536        block_10_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise_relu (ReLU)  (None, 8, 8, 384)    0           block_10_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_10_project (Conv2D)       (None, 8, 8, 96)     36864       block_10_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_10_project_BN (BatchNorma (None, 8, 8, 96)     384         block_10_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand (Conv2D)        (None, 8, 8, 576)    55296       block_10_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand_BN (BatchNormal (None, 8, 8, 576)    2304        block_11_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand_relu (ReLU)     (None, 8, 8, 576)    0           block_11_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise (DepthwiseCo (None, 8, 8, 576)    5184        block_11_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise_BN (BatchNor (None, 8, 8, 576)    2304        block_11_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise_relu (ReLU)  (None, 8, 8, 576)    0           block_11_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_11_project (Conv2D)       (None, 8, 8, 96)     55296       block_11_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_11_project_BN (BatchNorma (None, 8, 8, 96)     384         block_11_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_11_add (Add)              (None, 8, 8, 96)     0           block_10_project_BN[0][0]        \n",
      "                                                                 block_11_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand (Conv2D)        (None, 8, 8, 576)    55296       block_11_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand_BN (BatchNormal (None, 8, 8, 576)    2304        block_12_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand_relu (ReLU)     (None, 8, 8, 576)    0           block_12_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise (DepthwiseCo (None, 8, 8, 576)    5184        block_12_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise_BN (BatchNor (None, 8, 8, 576)    2304        block_12_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise_relu (ReLU)  (None, 8, 8, 576)    0           block_12_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_12_project (Conv2D)       (None, 8, 8, 96)     55296       block_12_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_12_project_BN (BatchNorma (None, 8, 8, 96)     384         block_12_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_12_add (Add)              (None, 8, 8, 96)     0           block_11_add[0][0]               \n",
      "                                                                 block_12_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand (Conv2D)        (None, 8, 8, 576)    55296       block_12_add[0][0]               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "block_13_expand_BN (BatchNormal (None, 8, 8, 576)    2304        block_13_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand_relu (ReLU)     (None, 8, 8, 576)    0           block_13_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_13_pad (ZeroPadding2D)    (None, 9, 9, 576)    0           block_13_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise (DepthwiseCo (None, 4, 4, 576)    5184        block_13_pad[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise_BN (BatchNor (None, 4, 4, 576)    2304        block_13_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise_relu (ReLU)  (None, 4, 4, 576)    0           block_13_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_13_project (Conv2D)       (None, 4, 4, 160)    92160       block_13_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_13_project_BN (BatchNorma (None, 4, 4, 160)    640         block_13_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand (Conv2D)        (None, 4, 4, 960)    153600      block_13_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand_BN (BatchNormal (None, 4, 4, 960)    3840        block_14_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand_relu (ReLU)     (None, 4, 4, 960)    0           block_14_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise (DepthwiseCo (None, 4, 4, 960)    8640        block_14_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise_BN (BatchNor (None, 4, 4, 960)    3840        block_14_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise_relu (ReLU)  (None, 4, 4, 960)    0           block_14_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_14_project (Conv2D)       (None, 4, 4, 160)    153600      block_14_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_14_project_BN (BatchNorma (None, 4, 4, 160)    640         block_14_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_14_add (Add)              (None, 4, 4, 160)    0           block_13_project_BN[0][0]        \n",
      "                                                                 block_14_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand (Conv2D)        (None, 4, 4, 960)    153600      block_14_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand_BN (BatchNormal (None, 4, 4, 960)    3840        block_15_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand_relu (ReLU)     (None, 4, 4, 960)    0           block_15_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise (DepthwiseCo (None, 4, 4, 960)    8640        block_15_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise_BN (BatchNor (None, 4, 4, 960)    3840        block_15_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise_relu (ReLU)  (None, 4, 4, 960)    0           block_15_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_15_project (Conv2D)       (None, 4, 4, 160)    153600      block_15_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_15_project_BN (BatchNorma (None, 4, 4, 160)    640         block_15_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_15_add (Add)              (None, 4, 4, 160)    0           block_14_add[0][0]               \n",
      "                                                                 block_15_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand (Conv2D)        (None, 4, 4, 960)    153600      block_15_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand_BN (BatchNormal (None, 4, 4, 960)    3840        block_16_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand_relu (ReLU)     (None, 4, 4, 960)    0           block_16_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise (DepthwiseCo (None, 4, 4, 960)    8640        block_16_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise_BN (BatchNor (None, 4, 4, 960)    3840        block_16_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise_relu (ReLU)  (None, 4, 4, 960)    0           block_16_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_16_project (Conv2D)       (None, 4, 4, 320)    307200      block_16_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_16_project_BN (BatchNorma (None, 4, 4, 320)    1280        block_16_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1 (Conv2D)                 (None, 4, 4, 1280)   409600      block_16_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1_bn (BatchNormalization)  (None, 4, 4, 1280)   5120        Conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "out_relu (ReLU)                 (None, 4, 4, 1280)   0           Conv_1_bn[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,257,984\n",
      "Trainable params: 2,223,872\n",
      "Non-trainable params: 34,112\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Freezing the base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining custom head for our network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'out_relu_1/Identity:0' shape=(None, 4, 4, 1280) dtype=float32>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'input_2:0' shape=(None, 128, 128, 3) dtype=float32>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'global_average_pooling2d_2/Identity:0' shape=(None, 1280) dtype=float32>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_average_pooling_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_layer1 = tf.keras.layers.Dense(units=128, activation='relu')(global_average_pooling_layer)\n",
    "custom_layer2 = tf.keras.layers.Dense(units=64, activation='relu')(custom_layer1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_layer = tf.keras.layers.Dense(units=1, activation='sigmoid')(custom_layer2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense_4/Identity:0' shape=(None, 1) dtype=float32>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Model(inputs=base_model.input, outputs=prediction_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 128, 128, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Conv1_pad (ZeroPadding2D)       (None, 129, 129, 3)  0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Conv1 (Conv2D)                  (None, 64, 64, 32)   864         Conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_Conv1 (BatchNormalization)   (None, 64, 64, 32)   128         Conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Conv1_relu (ReLU)               (None, 64, 64, 32)   0           bn_Conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise (Depthw (None, 64, 64, 32)   288         Conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise_BN (Bat (None, 64, 64, 32)   128         expanded_conv_depthwise[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise_relu (R (None, 64, 64, 32)   0           expanded_conv_depthwise_BN[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_project (Conv2D)  (None, 64, 64, 16)   512         expanded_conv_depthwise_relu[0][0\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_project_BN (Batch (None, 64, 64, 16)   64          expanded_conv_project[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand (Conv2D)         (None, 64, 64, 96)   1536        expanded_conv_project_BN[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand_BN (BatchNormali (None, 64, 64, 96)   384         block_1_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand_relu (ReLU)      (None, 64, 64, 96)   0           block_1_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_1_pad (ZeroPadding2D)     (None, 65, 65, 96)   0           block_1_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise (DepthwiseCon (None, 32, 32, 96)   864         block_1_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise_BN (BatchNorm (None, 32, 32, 96)   384         block_1_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise_relu (ReLU)   (None, 32, 32, 96)   0           block_1_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_1_project (Conv2D)        (None, 32, 32, 24)   2304        block_1_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_1_project_BN (BatchNormal (None, 32, 32, 24)   96          block_1_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand (Conv2D)         (None, 32, 32, 144)  3456        block_1_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand_BN (BatchNormali (None, 32, 32, 144)  576         block_2_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand_relu (ReLU)      (None, 32, 32, 144)  0           block_2_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise (DepthwiseCon (None, 32, 32, 144)  1296        block_2_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise_BN (BatchNorm (None, 32, 32, 144)  576         block_2_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise_relu (ReLU)   (None, 32, 32, 144)  0           block_2_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_2_project (Conv2D)        (None, 32, 32, 24)   3456        block_2_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_2_project_BN (BatchNormal (None, 32, 32, 24)   96          block_2_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2_add (Add)               (None, 32, 32, 24)   0           block_1_project_BN[0][0]         \n",
      "                                                                 block_2_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand (Conv2D)         (None, 32, 32, 144)  3456        block_2_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand_BN (BatchNormali (None, 32, 32, 144)  576         block_3_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand_relu (ReLU)      (None, 32, 32, 144)  0           block_3_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_3_pad (ZeroPadding2D)     (None, 33, 33, 144)  0           block_3_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise (DepthwiseCon (None, 16, 16, 144)  1296        block_3_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise_BN (BatchNorm (None, 16, 16, 144)  576         block_3_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise_relu (ReLU)   (None, 16, 16, 144)  0           block_3_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_3_project (Conv2D)        (None, 16, 16, 32)   4608        block_3_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_3_project_BN (BatchNormal (None, 16, 16, 32)   128         block_3_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand (Conv2D)         (None, 16, 16, 192)  6144        block_3_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand_BN (BatchNormali (None, 16, 16, 192)  768         block_4_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block_4_expand_relu (ReLU)      (None, 16, 16, 192)  0           block_4_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise (DepthwiseCon (None, 16, 16, 192)  1728        block_4_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise_BN (BatchNorm (None, 16, 16, 192)  768         block_4_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise_relu (ReLU)   (None, 16, 16, 192)  0           block_4_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_4_project (Conv2D)        (None, 16, 16, 32)   6144        block_4_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_4_project_BN (BatchNormal (None, 16, 16, 32)   128         block_4_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4_add (Add)               (None, 16, 16, 32)   0           block_3_project_BN[0][0]         \n",
      "                                                                 block_4_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand (Conv2D)         (None, 16, 16, 192)  6144        block_4_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand_BN (BatchNormali (None, 16, 16, 192)  768         block_5_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand_relu (ReLU)      (None, 16, 16, 192)  0           block_5_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise (DepthwiseCon (None, 16, 16, 192)  1728        block_5_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise_BN (BatchNorm (None, 16, 16, 192)  768         block_5_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise_relu (ReLU)   (None, 16, 16, 192)  0           block_5_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_5_project (Conv2D)        (None, 16, 16, 32)   6144        block_5_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_5_project_BN (BatchNormal (None, 16, 16, 32)   128         block_5_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_5_add (Add)               (None, 16, 16, 32)   0           block_4_add[0][0]                \n",
      "                                                                 block_5_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand (Conv2D)         (None, 16, 16, 192)  6144        block_5_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand_BN (BatchNormali (None, 16, 16, 192)  768         block_6_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand_relu (ReLU)      (None, 16, 16, 192)  0           block_6_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_6_pad (ZeroPadding2D)     (None, 17, 17, 192)  0           block_6_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise (DepthwiseCon (None, 8, 8, 192)    1728        block_6_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise_BN (BatchNorm (None, 8, 8, 192)    768         block_6_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise_relu (ReLU)   (None, 8, 8, 192)    0           block_6_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_6_project (Conv2D)        (None, 8, 8, 64)     12288       block_6_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_6_project_BN (BatchNormal (None, 8, 8, 64)     256         block_6_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand (Conv2D)         (None, 8, 8, 384)    24576       block_6_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand_BN (BatchNormali (None, 8, 8, 384)    1536        block_7_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand_relu (ReLU)      (None, 8, 8, 384)    0           block_7_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise (DepthwiseCon (None, 8, 8, 384)    3456        block_7_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise_BN (BatchNorm (None, 8, 8, 384)    1536        block_7_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise_relu (ReLU)   (None, 8, 8, 384)    0           block_7_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_7_project (Conv2D)        (None, 8, 8, 64)     24576       block_7_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_7_project_BN (BatchNormal (None, 8, 8, 64)     256         block_7_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_7_add (Add)               (None, 8, 8, 64)     0           block_6_project_BN[0][0]         \n",
      "                                                                 block_7_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand (Conv2D)         (None, 8, 8, 384)    24576       block_7_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand_BN (BatchNormali (None, 8, 8, 384)    1536        block_8_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand_relu (ReLU)      (None, 8, 8, 384)    0           block_8_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise (DepthwiseCon (None, 8, 8, 384)    3456        block_8_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise_BN (BatchNorm (None, 8, 8, 384)    1536        block_8_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise_relu (ReLU)   (None, 8, 8, 384)    0           block_8_depthwise_BN[0][0]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "block_8_project (Conv2D)        (None, 8, 8, 64)     24576       block_8_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_8_project_BN (BatchNormal (None, 8, 8, 64)     256         block_8_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_8_add (Add)               (None, 8, 8, 64)     0           block_7_add[0][0]                \n",
      "                                                                 block_8_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand (Conv2D)         (None, 8, 8, 384)    24576       block_8_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand_BN (BatchNormali (None, 8, 8, 384)    1536        block_9_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand_relu (ReLU)      (None, 8, 8, 384)    0           block_9_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise (DepthwiseCon (None, 8, 8, 384)    3456        block_9_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise_BN (BatchNorm (None, 8, 8, 384)    1536        block_9_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise_relu (ReLU)   (None, 8, 8, 384)    0           block_9_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_9_project (Conv2D)        (None, 8, 8, 64)     24576       block_9_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_9_project_BN (BatchNormal (None, 8, 8, 64)     256         block_9_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_9_add (Add)               (None, 8, 8, 64)     0           block_8_add[0][0]                \n",
      "                                                                 block_9_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand (Conv2D)        (None, 8, 8, 384)    24576       block_9_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand_BN (BatchNormal (None, 8, 8, 384)    1536        block_10_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand_relu (ReLU)     (None, 8, 8, 384)    0           block_10_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise (DepthwiseCo (None, 8, 8, 384)    3456        block_10_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise_BN (BatchNor (None, 8, 8, 384)    1536        block_10_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise_relu (ReLU)  (None, 8, 8, 384)    0           block_10_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_10_project (Conv2D)       (None, 8, 8, 96)     36864       block_10_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_10_project_BN (BatchNorma (None, 8, 8, 96)     384         block_10_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand (Conv2D)        (None, 8, 8, 576)    55296       block_10_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand_BN (BatchNormal (None, 8, 8, 576)    2304        block_11_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand_relu (ReLU)     (None, 8, 8, 576)    0           block_11_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise (DepthwiseCo (None, 8, 8, 576)    5184        block_11_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise_BN (BatchNor (None, 8, 8, 576)    2304        block_11_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise_relu (ReLU)  (None, 8, 8, 576)    0           block_11_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_11_project (Conv2D)       (None, 8, 8, 96)     55296       block_11_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_11_project_BN (BatchNorma (None, 8, 8, 96)     384         block_11_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_11_add (Add)              (None, 8, 8, 96)     0           block_10_project_BN[0][0]        \n",
      "                                                                 block_11_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand (Conv2D)        (None, 8, 8, 576)    55296       block_11_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand_BN (BatchNormal (None, 8, 8, 576)    2304        block_12_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand_relu (ReLU)     (None, 8, 8, 576)    0           block_12_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise (DepthwiseCo (None, 8, 8, 576)    5184        block_12_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise_BN (BatchNor (None, 8, 8, 576)    2304        block_12_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise_relu (ReLU)  (None, 8, 8, 576)    0           block_12_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_12_project (Conv2D)       (None, 8, 8, 96)     55296       block_12_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_12_project_BN (BatchNorma (None, 8, 8, 96)     384         block_12_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_12_add (Add)              (None, 8, 8, 96)     0           block_11_add[0][0]               \n",
      "                                                                 block_12_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand (Conv2D)        (None, 8, 8, 576)    55296       block_12_add[0][0]               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "block_13_expand_BN (BatchNormal (None, 8, 8, 576)    2304        block_13_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand_relu (ReLU)     (None, 8, 8, 576)    0           block_13_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_13_pad (ZeroPadding2D)    (None, 9, 9, 576)    0           block_13_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise (DepthwiseCo (None, 4, 4, 576)    5184        block_13_pad[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise_BN (BatchNor (None, 4, 4, 576)    2304        block_13_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise_relu (ReLU)  (None, 4, 4, 576)    0           block_13_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_13_project (Conv2D)       (None, 4, 4, 160)    92160       block_13_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_13_project_BN (BatchNorma (None, 4, 4, 160)    640         block_13_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand (Conv2D)        (None, 4, 4, 960)    153600      block_13_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand_BN (BatchNormal (None, 4, 4, 960)    3840        block_14_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand_relu (ReLU)     (None, 4, 4, 960)    0           block_14_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise (DepthwiseCo (None, 4, 4, 960)    8640        block_14_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise_BN (BatchNor (None, 4, 4, 960)    3840        block_14_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise_relu (ReLU)  (None, 4, 4, 960)    0           block_14_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_14_project (Conv2D)       (None, 4, 4, 160)    153600      block_14_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_14_project_BN (BatchNorma (None, 4, 4, 160)    640         block_14_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_14_add (Add)              (None, 4, 4, 160)    0           block_13_project_BN[0][0]        \n",
      "                                                                 block_14_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand (Conv2D)        (None, 4, 4, 960)    153600      block_14_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand_BN (BatchNormal (None, 4, 4, 960)    3840        block_15_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand_relu (ReLU)     (None, 4, 4, 960)    0           block_15_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise (DepthwiseCo (None, 4, 4, 960)    8640        block_15_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise_BN (BatchNor (None, 4, 4, 960)    3840        block_15_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise_relu (ReLU)  (None, 4, 4, 960)    0           block_15_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_15_project (Conv2D)       (None, 4, 4, 160)    153600      block_15_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_15_project_BN (BatchNorma (None, 4, 4, 160)    640         block_15_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_15_add (Add)              (None, 4, 4, 160)    0           block_14_add[0][0]               \n",
      "                                                                 block_15_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand (Conv2D)        (None, 4, 4, 960)    153600      block_15_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand_BN (BatchNormal (None, 4, 4, 960)    3840        block_16_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand_relu (ReLU)     (None, 4, 4, 960)    0           block_16_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise (DepthwiseCo (None, 4, 4, 960)    8640        block_16_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise_BN (BatchNor (None, 4, 4, 960)    3840        block_16_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise_relu (ReLU)  (None, 4, 4, 960)    0           block_16_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_16_project (Conv2D)       (None, 4, 4, 320)    307200      block_16_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_16_project_BN (BatchNorma (None, 4, 4, 320)    1280        block_16_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1 (Conv2D)                 (None, 4, 4, 1280)   409600      block_16_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1_bn (BatchNormalization)  (None, 4, 4, 1280)   5120        Conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "out_relu (ReLU)                 (None, 4, 4, 1280)   0           Conv_1_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 1280)         0           out_relu[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          163968      global_average_pooling2d_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 64)           8256        dense_2[0][0]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            65          dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 2,430,273\n",
      "Trainable params: 172,289\n",
      "Non-trainable params: 2,257,984\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=0.0001), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen_train = ImageDataGenerator(rescale=255.)\n",
    "data_gen_test = ImageDataGenerator(rescale=255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = data_gen_train.flow_from_directory(train_dir, target_size=(128, 128), class_mode='binary')\n",
    "validation_generator = data_gen_test.flow_from_directory(validation_dir, target_size = (128, 128), class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 63 steps, validate for 32 steps\n",
      "Epoch 1/15\n",
      "63/63 [==============================] - ETA: 2:44 - loss: 0.7855 - accuracy: 0.40 - ETA: 1:26 - loss: 0.7343 - accuracy: 0.48 - ETA: 1:00 - loss: 0.6808 - accuracy: 0.56 - ETA: 47s - loss: 0.6633 - accuracy: 0.5859 - ETA: 40s - loss: 0.6591 - accuracy: 0.593 - ETA: 34s - loss: 0.6495 - accuracy: 0.604 - ETA: 30s - loss: 0.6468 - accuracy: 0.601 - ETA: 27s - loss: 0.6404 - accuracy: 0.620 - ETA: 24s - loss: 0.6348 - accuracy: 0.621 - ETA: 22s - loss: 0.6327 - accuracy: 0.628 - ETA: 21s - loss: 0.6240 - accuracy: 0.639 - ETA: 20s - loss: 0.6181 - accuracy: 0.646 - ETA: 18s - loss: 0.6059 - accuracy: 0.665 - ETA: 17s - loss: 0.5989 - accuracy: 0.678 - ETA: 16s - loss: 0.5916 - accuracy: 0.694 - ETA: 16s - loss: 0.5857 - accuracy: 0.703 - ETA: 15s - loss: 0.5883 - accuracy: 0.695 - ETA: 14s - loss: 0.5809 - accuracy: 0.705 - ETA: 14s - loss: 0.5725 - accuracy: 0.716 - ETA: 13s - loss: 0.5687 - accuracy: 0.721 - ETA: 12s - loss: 0.5682 - accuracy: 0.724 - ETA: 12s - loss: 0.5607 - accuracy: 0.732 - ETA: 11s - loss: 0.5532 - accuracy: 0.740 - ETA: 11s - loss: 0.5484 - accuracy: 0.744 - ETA: 10s - loss: 0.5415 - accuracy: 0.751 - ETA: 10s - loss: 0.5369 - accuracy: 0.754 - ETA: 10s - loss: 0.5309 - accuracy: 0.759 - ETA: 9s - loss: 0.5269 - accuracy: 0.762 - ETA: 9s - loss: 0.5249 - accuracy: 0.76 - ETA: 8s - loss: 0.5198 - accuracy: 0.76 - ETA: 8s - loss: 0.5180 - accuracy: 0.76 - ETA: 8s - loss: 0.5135 - accuracy: 0.77 - ETA: 7s - loss: 0.5141 - accuracy: 0.77 - ETA: 7s - loss: 0.5082 - accuracy: 0.77 - ETA: 7s - loss: 0.5070 - accuracy: 0.77 - ETA: 6s - loss: 0.5046 - accuracy: 0.77 - ETA: 6s - loss: 0.5028 - accuracy: 0.77 - ETA: 6s - loss: 0.4976 - accuracy: 0.78 - ETA: 6s - loss: 0.4949 - accuracy: 0.78 - ETA: 5s - loss: 0.4936 - accuracy: 0.78 - ETA: 5s - loss: 0.4914 - accuracy: 0.78 - ETA: 5s - loss: 0.4914 - accuracy: 0.78 - ETA: 4s - loss: 0.4862 - accuracy: 0.78 - ETA: 4s - loss: 0.4805 - accuracy: 0.79 - ETA: 4s - loss: 0.4793 - accuracy: 0.79 - ETA: 4s - loss: 0.4787 - accuracy: 0.79 - ETA: 3s - loss: 0.4754 - accuracy: 0.79 - ETA: 3s - loss: 0.4715 - accuracy: 0.79 - ETA: 3s - loss: 0.4696 - accuracy: 0.79 - ETA: 3s - loss: 0.4656 - accuracy: 0.80 - ETA: 2s - loss: 0.4624 - accuracy: 0.80 - ETA: 2s - loss: 0.4599 - accuracy: 0.80 - ETA: 2s - loss: 0.4578 - accuracy: 0.80 - ETA: 2s - loss: 0.4550 - accuracy: 0.80 - ETA: 1s - loss: 0.4516 - accuracy: 0.80 - ETA: 1s - loss: 0.4521 - accuracy: 0.80 - ETA: 1s - loss: 0.4498 - accuracy: 0.81 - ETA: 1s - loss: 0.4468 - accuracy: 0.81 - ETA: 0s - loss: 0.4439 - accuracy: 0.81 - ETA: 0s - loss: 0.4395 - accuracy: 0.81 - ETA: 0s - loss: 0.4375 - accuracy: 0.81 - ETA: 0s - loss: 0.4350 - accuracy: 0.81 - 21s 338ms/step - loss: 0.4315 - accuracy: 0.8215 - val_loss: 0.7401 - val_accuracy: 0.4690\n",
      "Epoch 2/15\n",
      "63/63 [==============================] - ETA: 22s - loss: 0.2676 - accuracy: 0.906 - ETA: 16s - loss: 0.2371 - accuracy: 0.906 - ETA: 15s - loss: 0.2357 - accuracy: 0.906 - ETA: 14s - loss: 0.2249 - accuracy: 0.906 - ETA: 12s - loss: 0.2312 - accuracy: 0.909 - ETA: 12s - loss: 0.2438 - accuracy: 0.897 - ETA: 11s - loss: 0.2518 - accuracy: 0.894 - ETA: 11s - loss: 0.2481 - accuracy: 0.904 - ETA: 11s - loss: 0.2485 - accuracy: 0.908 - ETA: 11s - loss: 0.2477 - accuracy: 0.907 - ETA: 10s - loss: 0.2428 - accuracy: 0.910 - ETA: 10s - loss: 0.2420 - accuracy: 0.913 - ETA: 10s - loss: 0.2393 - accuracy: 0.915 - ETA: 10s - loss: 0.2402 - accuracy: 0.914 - ETA: 9s - loss: 0.2347 - accuracy: 0.918 - ETA: 9s - loss: 0.2351 - accuracy: 0.91 - ETA: 9s - loss: 0.2337 - accuracy: 0.92 - ETA: 9s - loss: 0.2373 - accuracy: 0.91 - ETA: 8s - loss: 0.2338 - accuracy: 0.92 - ETA: 8s - loss: 0.2368 - accuracy: 0.91 - ETA: 8s - loss: 0.2397 - accuracy: 0.91 - ETA: 8s - loss: 0.2416 - accuracy: 0.91 - ETA: 8s - loss: 0.2404 - accuracy: 0.91 - ETA: 7s - loss: 0.2367 - accuracy: 0.91 - ETA: 7s - loss: 0.2331 - accuracy: 0.92 - ETA: 7s - loss: 0.2425 - accuracy: 0.91 - ETA: 7s - loss: 0.2419 - accuracy: 0.91 - ETA: 7s - loss: 0.2401 - accuracy: 0.91 - ETA: 6s - loss: 0.2366 - accuracy: 0.91 - ETA: 6s - loss: 0.2376 - accuracy: 0.91 - ETA: 6s - loss: 0.2350 - accuracy: 0.91 - ETA: 6s - loss: 0.2377 - accuracy: 0.91 - ETA: 5s - loss: 0.2356 - accuracy: 0.91 - ETA: 5s - loss: 0.2340 - accuracy: 0.91 - ETA: 5s - loss: 0.2352 - accuracy: 0.91 - ETA: 5s - loss: 0.2348 - accuracy: 0.91 - ETA: 5s - loss: 0.2336 - accuracy: 0.91 - ETA: 4s - loss: 0.2326 - accuracy: 0.91 - ETA: 4s - loss: 0.2326 - accuracy: 0.91 - ETA: 4s - loss: 0.2316 - accuracy: 0.91 - ETA: 4s - loss: 0.2313 - accuracy: 0.91 - ETA: 4s - loss: 0.2346 - accuracy: 0.91 - ETA: 3s - loss: 0.2321 - accuracy: 0.91 - ETA: 3s - loss: 0.2307 - accuracy: 0.91 - ETA: 3s - loss: 0.2282 - accuracy: 0.91 - ETA: 3s - loss: 0.2276 - accuracy: 0.91 - ETA: 3s - loss: 0.2247 - accuracy: 0.92 - ETA: 2s - loss: 0.2239 - accuracy: 0.92 - ETA: 2s - loss: 0.2231 - accuracy: 0.92 - ETA: 2s - loss: 0.2251 - accuracy: 0.91 - ETA: 2s - loss: 0.2260 - accuracy: 0.91 - ETA: 2s - loss: 0.2271 - accuracy: 0.91 - ETA: 1s - loss: 0.2283 - accuracy: 0.91 - ETA: 1s - loss: 0.2259 - accuracy: 0.91 - ETA: 1s - loss: 0.2253 - accuracy: 0.91 - ETA: 1s - loss: 0.2245 - accuracy: 0.92 - ETA: 1s - loss: 0.2259 - accuracy: 0.91 - ETA: 0s - loss: 0.2248 - accuracy: 0.92 - ETA: 0s - loss: 0.2257 - accuracy: 0.91 - ETA: 0s - loss: 0.2236 - accuracy: 0.92 - ETA: 0s - loss: 0.2234 - accuracy: 0.92 - ETA: 0s - loss: 0.2232 - accuracy: 0.92 - 18s 286ms/step - loss: 0.2247 - accuracy: 0.9190 - val_loss: 0.8181 - val_accuracy: 0.4930\n",
      "Epoch 3/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - ETA: 20s - loss: 0.1391 - accuracy: 0.937 - ETA: 16s - loss: 0.1790 - accuracy: 0.921 - ETA: 14s - loss: 0.1777 - accuracy: 0.947 - ETA: 13s - loss: 0.1529 - accuracy: 0.960 - ETA: 13s - loss: 0.1475 - accuracy: 0.956 - ETA: 12s - loss: 0.1509 - accuracy: 0.958 - ETA: 12s - loss: 0.1510 - accuracy: 0.959 - ETA: 11s - loss: 0.1549 - accuracy: 0.960 - ETA: 11s - loss: 0.1611 - accuracy: 0.954 - ETA: 11s - loss: 0.1615 - accuracy: 0.953 - ETA: 11s - loss: 0.1681 - accuracy: 0.946 - ETA: 10s - loss: 0.1680 - accuracy: 0.947 - ETA: 10s - loss: 0.1644 - accuracy: 0.947 - ETA: 10s - loss: 0.1701 - accuracy: 0.939 - ETA: 10s - loss: 0.1653 - accuracy: 0.941 - ETA: 9s - loss: 0.1691 - accuracy: 0.939 - ETA: 9s - loss: 0.1642 - accuracy: 0.94 - ETA: 9s - loss: 0.1728 - accuracy: 0.93 - ETA: 9s - loss: 0.1725 - accuracy: 0.93 - ETA: 8s - loss: 0.1680 - accuracy: 0.93 - ETA: 8s - loss: 0.1683 - accuracy: 0.93 - ETA: 8s - loss: 0.1674 - accuracy: 0.93 - ETA: 8s - loss: 0.1681 - accuracy: 0.93 - ETA: 8s - loss: 0.1667 - accuracy: 0.93 - ETA: 7s - loss: 0.1692 - accuracy: 0.93 - ETA: 7s - loss: 0.1685 - accuracy: 0.93 - ETA: 7s - loss: 0.1682 - accuracy: 0.93 - ETA: 7s - loss: 0.1651 - accuracy: 0.93 - ETA: 6s - loss: 0.1647 - accuracy: 0.93 - ETA: 6s - loss: 0.1645 - accuracy: 0.93 - ETA: 6s - loss: 0.1627 - accuracy: 0.94 - ETA: 6s - loss: 0.1616 - accuracy: 0.94 - ETA: 6s - loss: 0.1613 - accuracy: 0.94 - ETA: 5s - loss: 0.1628 - accuracy: 0.94 - ETA: 5s - loss: 0.1635 - accuracy: 0.93 - ETA: 5s - loss: 0.1625 - accuracy: 0.93 - ETA: 5s - loss: 0.1614 - accuracy: 0.94 - ETA: 4s - loss: 0.1599 - accuracy: 0.94 - ETA: 4s - loss: 0.1595 - accuracy: 0.94 - ETA: 4s - loss: 0.1575 - accuracy: 0.94 - ETA: 4s - loss: 0.1554 - accuracy: 0.94 - ETA: 4s - loss: 0.1623 - accuracy: 0.94 - ETA: 3s - loss: 0.1637 - accuracy: 0.94 - ETA: 3s - loss: 0.1629 - accuracy: 0.94 - ETA: 3s - loss: 0.1633 - accuracy: 0.94 - ETA: 3s - loss: 0.1637 - accuracy: 0.94 - ETA: 3s - loss: 0.1654 - accuracy: 0.93 - ETA: 2s - loss: 0.1660 - accuracy: 0.93 - ETA: 2s - loss: 0.1650 - accuracy: 0.93 - ETA: 2s - loss: 0.1631 - accuracy: 0.94 - ETA: 2s - loss: 0.1623 - accuracy: 0.94 - ETA: 2s - loss: 0.1614 - accuracy: 0.94 - ETA: 1s - loss: 0.1631 - accuracy: 0.93 - ETA: 1s - loss: 0.1620 - accuracy: 0.94 - ETA: 1s - loss: 0.1622 - accuracy: 0.94 - ETA: 1s - loss: 0.1601 - accuracy: 0.94 - ETA: 1s - loss: 0.1620 - accuracy: 0.94 - ETA: 0s - loss: 0.1640 - accuracy: 0.93 - ETA: 0s - loss: 0.1632 - accuracy: 0.94 - ETA: 0s - loss: 0.1646 - accuracy: 0.93 - ETA: 0s - loss: 0.1638 - accuracy: 0.94 - ETA: 0s - loss: 0.1624 - accuracy: 0.94 - 18s 283ms/step - loss: 0.1634 - accuracy: 0.9395 - val_loss: 0.9135 - val_accuracy: 0.5040\n",
      "Epoch 4/15\n",
      "63/63 [==============================] - ETA: 20s - loss: 0.0626 - accuracy: 1.000 - ETA: 15s - loss: 0.1352 - accuracy: 0.953 - ETA: 14s - loss: 0.1110 - accuracy: 0.968 - ETA: 13s - loss: 0.1178 - accuracy: 0.968 - ETA: 12s - loss: 0.1149 - accuracy: 0.968 - ETA: 12s - loss: 0.1183 - accuracy: 0.974 - ETA: 12s - loss: 0.1112 - accuracy: 0.977 - ETA: 11s - loss: 0.1143 - accuracy: 0.972 - ETA: 11s - loss: 0.1230 - accuracy: 0.965 - ETA: 11s - loss: 0.1233 - accuracy: 0.962 - ETA: 10s - loss: 0.1355 - accuracy: 0.954 - ETA: 10s - loss: 0.1273 - accuracy: 0.958 - ETA: 10s - loss: 0.1404 - accuracy: 0.951 - ETA: 9s - loss: 0.1389 - accuracy: 0.953 - ETA: 9s - loss: 0.1402 - accuracy: 0.95 - ETA: 9s - loss: 0.1385 - accuracy: 0.95 - ETA: 9s - loss: 0.1409 - accuracy: 0.94 - ETA: 9s - loss: 0.1438 - accuracy: 0.94 - ETA: 8s - loss: 0.1400 - accuracy: 0.94 - ETA: 8s - loss: 0.1382 - accuracy: 0.95 - ETA: 8s - loss: 0.1359 - accuracy: 0.95 - ETA: 8s - loss: 0.1344 - accuracy: 0.95 - ETA: 7s - loss: 0.1309 - accuracy: 0.95 - ETA: 7s - loss: 0.1280 - accuracy: 0.95 - ETA: 7s - loss: 0.1274 - accuracy: 0.95 - ETA: 7s - loss: 0.1261 - accuracy: 0.95 - ETA: 7s - loss: 0.1271 - accuracy: 0.95 - ETA: 6s - loss: 0.1286 - accuracy: 0.95 - ETA: 6s - loss: 0.1275 - accuracy: 0.95 - ETA: 6s - loss: 0.1278 - accuracy: 0.95 - ETA: 6s - loss: 0.1291 - accuracy: 0.94 - ETA: 6s - loss: 0.1276 - accuracy: 0.95 - ETA: 5s - loss: 0.1325 - accuracy: 0.94 - ETA: 5s - loss: 0.1348 - accuracy: 0.94 - ETA: 5s - loss: 0.1342 - accuracy: 0.94 - ETA: 5s - loss: 0.1315 - accuracy: 0.94 - ETA: 5s - loss: 0.1304 - accuracy: 0.94 - ETA: 4s - loss: 0.1339 - accuracy: 0.94 - ETA: 4s - loss: 0.1337 - accuracy: 0.94 - ETA: 4s - loss: 0.1339 - accuracy: 0.94 - ETA: 4s - loss: 0.1325 - accuracy: 0.94 - ETA: 4s - loss: 0.1359 - accuracy: 0.94 - ETA: 3s - loss: 0.1347 - accuracy: 0.94 - ETA: 3s - loss: 0.1350 - accuracy: 0.94 - ETA: 3s - loss: 0.1350 - accuracy: 0.94 - ETA: 3s - loss: 0.1347 - accuracy: 0.94 - ETA: 3s - loss: 0.1341 - accuracy: 0.94 - ETA: 2s - loss: 0.1352 - accuracy: 0.94 - ETA: 2s - loss: 0.1343 - accuracy: 0.94 - ETA: 2s - loss: 0.1331 - accuracy: 0.94 - ETA: 2s - loss: 0.1330 - accuracy: 0.94 - ETA: 2s - loss: 0.1320 - accuracy: 0.94 - ETA: 1s - loss: 0.1309 - accuracy: 0.94 - ETA: 1s - loss: 0.1318 - accuracy: 0.94 - ETA: 1s - loss: 0.1320 - accuracy: 0.94 - ETA: 1s - loss: 0.1313 - accuracy: 0.94 - ETA: 1s - loss: 0.1328 - accuracy: 0.94 - ETA: 0s - loss: 0.1319 - accuracy: 0.94 - ETA: 0s - loss: 0.1321 - accuracy: 0.94 - ETA: 0s - loss: 0.1321 - accuracy: 0.94 - ETA: 0s - loss: 0.1317 - accuracy: 0.94 - ETA: 0s - loss: 0.1310 - accuracy: 0.94 - 18s 286ms/step - loss: 0.1316 - accuracy: 0.9480 - val_loss: 0.9144 - val_accuracy: 0.5020\n",
      "Epoch 5/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - ETA: 18s - loss: 0.1058 - accuracy: 0.968 - ETA: 15s - loss: 0.1347 - accuracy: 0.953 - ETA: 13s - loss: 0.1040 - accuracy: 0.968 - ETA: 13s - loss: 0.1206 - accuracy: 0.968 - ETA: 12s - loss: 0.1503 - accuracy: 0.937 - ETA: 12s - loss: 0.1609 - accuracy: 0.932 - ETA: 11s - loss: 0.1536 - accuracy: 0.937 - ETA: 11s - loss: 0.1532 - accuracy: 0.941 - ETA: 11s - loss: 0.1456 - accuracy: 0.944 - ETA: 10s - loss: 0.1425 - accuracy: 0.943 - ETA: 10s - loss: 0.1340 - accuracy: 0.948 - ETA: 10s - loss: 0.1286 - accuracy: 0.953 - ETA: 10s - loss: 0.1231 - accuracy: 0.954 - ETA: 9s - loss: 0.1275 - accuracy: 0.955 - ETA: 9s - loss: 0.1226 - accuracy: 0.95 - ETA: 9s - loss: 0.1197 - accuracy: 0.95 - ETA: 9s - loss: 0.1184 - accuracy: 0.95 - ETA: 8s - loss: 0.1189 - accuracy: 0.96 - ETA: 8s - loss: 0.1178 - accuracy: 0.96 - ETA: 8s - loss: 0.1150 - accuracy: 0.96 - ETA: 8s - loss: 0.1144 - accuracy: 0.96 - ETA: 8s - loss: 0.1148 - accuracy: 0.96 - ETA: 7s - loss: 0.1134 - accuracy: 0.96 - ETA: 7s - loss: 0.1121 - accuracy: 0.96 - ETA: 7s - loss: 0.1124 - accuracy: 0.96 - ETA: 7s - loss: 0.1146 - accuracy: 0.96 - ETA: 7s - loss: 0.1150 - accuracy: 0.96 - ETA: 6s - loss: 0.1139 - accuracy: 0.96 - ETA: 6s - loss: 0.1129 - accuracy: 0.96 - ETA: 6s - loss: 0.1124 - accuracy: 0.96 - ETA: 6s - loss: 0.1111 - accuracy: 0.96 - ETA: 6s - loss: 0.1112 - accuracy: 0.96 - ETA: 5s - loss: 0.1091 - accuracy: 0.96 - ETA: 5s - loss: 0.1107 - accuracy: 0.96 - ETA: 5s - loss: 0.1104 - accuracy: 0.96 - ETA: 5s - loss: 0.1105 - accuracy: 0.96 - ETA: 5s - loss: 0.1088 - accuracy: 0.96 - ETA: 4s - loss: 0.1074 - accuracy: 0.96 - ETA: 4s - loss: 0.1091 - accuracy: 0.96 - ETA: 4s - loss: 0.1083 - accuracy: 0.96 - ETA: 4s - loss: 0.1095 - accuracy: 0.96 - ETA: 4s - loss: 0.1082 - accuracy: 0.96 - ETA: 3s - loss: 0.1075 - accuracy: 0.96 - ETA: 3s - loss: 0.1078 - accuracy: 0.96 - ETA: 3s - loss: 0.1059 - accuracy: 0.96 - ETA: 3s - loss: 0.1050 - accuracy: 0.96 - ETA: 3s - loss: 0.1045 - accuracy: 0.96 - ETA: 2s - loss: 0.1049 - accuracy: 0.96 - ETA: 2s - loss: 0.1057 - accuracy: 0.96 - ETA: 2s - loss: 0.1073 - accuracy: 0.96 - ETA: 2s - loss: 0.1095 - accuracy: 0.96 - ETA: 2s - loss: 0.1105 - accuracy: 0.96 - ETA: 1s - loss: 0.1100 - accuracy: 0.96 - ETA: 1s - loss: 0.1108 - accuracy: 0.96 - ETA: 1s - loss: 0.1106 - accuracy: 0.96 - ETA: 1s - loss: 0.1106 - accuracy: 0.96 - ETA: 1s - loss: 0.1097 - accuracy: 0.96 - ETA: 0s - loss: 0.1097 - accuracy: 0.96 - ETA: 0s - loss: 0.1091 - accuracy: 0.96 - ETA: 0s - loss: 0.1092 - accuracy: 0.96 - ETA: 0s - loss: 0.1115 - accuracy: 0.96 - ETA: 0s - loss: 0.1104 - accuracy: 0.96 - 18s 280ms/step - loss: 0.1100 - accuracy: 0.9615 - val_loss: 0.9952 - val_accuracy: 0.5060\n",
      "Epoch 6/15\n",
      "63/63 [==============================] - ETA: 20s - loss: 0.0858 - accuracy: 0.968 - ETA: 15s - loss: 0.0837 - accuracy: 0.984 - ETA: 14s - loss: 0.0919 - accuracy: 0.979 - ETA: 13s - loss: 0.0879 - accuracy: 0.976 - ETA: 12s - loss: 0.0854 - accuracy: 0.981 - ETA: 12s - loss: 0.0825 - accuracy: 0.979 - ETA: 11s - loss: 0.0810 - accuracy: 0.977 - ETA: 11s - loss: 0.0897 - accuracy: 0.968 - ETA: 11s - loss: 0.0841 - accuracy: 0.972 - ETA: 11s - loss: 0.0894 - accuracy: 0.968 - ETA: 10s - loss: 0.0925 - accuracy: 0.965 - ETA: 10s - loss: 0.0920 - accuracy: 0.966 - ETA: 10s - loss: 0.0870 - accuracy: 0.968 - ETA: 9s - loss: 0.0859 - accuracy: 0.971 - ETA: 9s - loss: 0.0895 - accuracy: 0.97 - ETA: 9s - loss: 0.0868 - accuracy: 0.97 - ETA: 9s - loss: 0.0855 - accuracy: 0.97 - ETA: 9s - loss: 0.0845 - accuracy: 0.97 - ETA: 8s - loss: 0.0893 - accuracy: 0.97 - ETA: 8s - loss: 0.0923 - accuracy: 0.97 - ETA: 8s - loss: 0.0889 - accuracy: 0.97 - ETA: 8s - loss: 0.0919 - accuracy: 0.97 - ETA: 7s - loss: 0.0907 - accuracy: 0.97 - ETA: 7s - loss: 0.0899 - accuracy: 0.97 - ETA: 7s - loss: 0.0903 - accuracy: 0.97 - ETA: 7s - loss: 0.0944 - accuracy: 0.97 - ETA: 7s - loss: 0.0928 - accuracy: 0.97 - ETA: 6s - loss: 0.0966 - accuracy: 0.97 - ETA: 6s - loss: 0.0964 - accuracy: 0.97 - ETA: 6s - loss: 0.0943 - accuracy: 0.97 - ETA: 6s - loss: 0.0937 - accuracy: 0.97 - ETA: 6s - loss: 0.0928 - accuracy: 0.97 - ETA: 5s - loss: 0.0925 - accuracy: 0.97 - ETA: 5s - loss: 0.0916 - accuracy: 0.97 - ETA: 5s - loss: 0.0924 - accuracy: 0.97 - ETA: 5s - loss: 0.0916 - accuracy: 0.97 - ETA: 5s - loss: 0.0911 - accuracy: 0.97 - ETA: 4s - loss: 0.0899 - accuracy: 0.97 - ETA: 4s - loss: 0.0891 - accuracy: 0.97 - ETA: 4s - loss: 0.0909 - accuracy: 0.97 - ETA: 4s - loss: 0.0923 - accuracy: 0.97 - ETA: 4s - loss: 0.0925 - accuracy: 0.97 - ETA: 3s - loss: 0.0911 - accuracy: 0.97 - ETA: 3s - loss: 0.0930 - accuracy: 0.97 - ETA: 3s - loss: 0.0931 - accuracy: 0.97 - ETA: 3s - loss: 0.0926 - accuracy: 0.97 - ETA: 3s - loss: 0.0915 - accuracy: 0.97 - ETA: 2s - loss: 0.0906 - accuracy: 0.97 - ETA: 2s - loss: 0.0912 - accuracy: 0.97 - ETA: 2s - loss: 0.0931 - accuracy: 0.97 - ETA: 2s - loss: 0.0929 - accuracy: 0.97 - ETA: 2s - loss: 0.0919 - accuracy: 0.97 - ETA: 1s - loss: 0.0912 - accuracy: 0.97 - ETA: 1s - loss: 0.0911 - accuracy: 0.97 - ETA: 1s - loss: 0.0915 - accuracy: 0.97 - ETA: 1s - loss: 0.0913 - accuracy: 0.97 - ETA: 1s - loss: 0.0921 - accuracy: 0.97 - ETA: 0s - loss: 0.0914 - accuracy: 0.97 - ETA: 0s - loss: 0.0904 - accuracy: 0.97 - ETA: 0s - loss: 0.0910 - accuracy: 0.97 - ETA: 0s - loss: 0.0917 - accuracy: 0.97 - ETA: 0s - loss: 0.0912 - accuracy: 0.97 - 18s 280ms/step - loss: 0.0915 - accuracy: 0.9700 - val_loss: 1.1060 - val_accuracy: 0.5030\n",
      "Epoch 7/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - ETA: 19s - loss: 0.0774 - accuracy: 1.000 - ETA: 15s - loss: 0.0683 - accuracy: 1.000 - ETA: 14s - loss: 0.0576 - accuracy: 1.000 - ETA: 13s - loss: 0.0547 - accuracy: 1.000 - ETA: 12s - loss: 0.0522 - accuracy: 1.000 - ETA: 12s - loss: 0.0516 - accuracy: 0.994 - ETA: 11s - loss: 0.0618 - accuracy: 0.991 - ETA: 11s - loss: 0.0663 - accuracy: 0.988 - ETA: 11s - loss: 0.0676 - accuracy: 0.986 - ETA: 10s - loss: 0.0633 - accuracy: 0.987 - ETA: 10s - loss: 0.0604 - accuracy: 0.988 - ETA: 10s - loss: 0.0623 - accuracy: 0.987 - ETA: 10s - loss: 0.0638 - accuracy: 0.985 - ETA: 9s - loss: 0.0678 - accuracy: 0.984 - ETA: 9s - loss: 0.0682 - accuracy: 0.98 - ETA: 9s - loss: 0.0680 - accuracy: 0.98 - ETA: 9s - loss: 0.0696 - accuracy: 0.98 - ETA: 9s - loss: 0.0685 - accuracy: 0.98 - ETA: 8s - loss: 0.0673 - accuracy: 0.98 - ETA: 8s - loss: 0.0663 - accuracy: 0.98 - ETA: 8s - loss: 0.0662 - accuracy: 0.98 - ETA: 7s - loss: 0.0660 - accuracy: 0.98 - ETA: 7s - loss: 0.0654 - accuracy: 0.98 - ETA: 7s - loss: 0.0655 - accuracy: 0.98 - ETA: 7s - loss: 0.0704 - accuracy: 0.98 - ETA: 7s - loss: 0.0685 - accuracy: 0.98 - ETA: 6s - loss: 0.0695 - accuracy: 0.98 - ETA: 6s - loss: 0.0699 - accuracy: 0.98 - ETA: 6s - loss: 0.0690 - accuracy: 0.98 - ETA: 6s - loss: 0.0683 - accuracy: 0.98 - ETA: 6s - loss: 0.0714 - accuracy: 0.98 - ETA: 6s - loss: 0.0707 - accuracy: 0.98 - ETA: 5s - loss: 0.0705 - accuracy: 0.98 - ETA: 5s - loss: 0.0693 - accuracy: 0.98 - ETA: 5s - loss: 0.0689 - accuracy: 0.98 - ETA: 5s - loss: 0.0693 - accuracy: 0.98 - ETA: 5s - loss: 0.0705 - accuracy: 0.98 - ETA: 4s - loss: 0.0700 - accuracy: 0.98 - ETA: 4s - loss: 0.0702 - accuracy: 0.98 - ETA: 4s - loss: 0.0694 - accuracy: 0.98 - ETA: 4s - loss: 0.0706 - accuracy: 0.98 - ETA: 4s - loss: 0.0712 - accuracy: 0.98 - ETA: 3s - loss: 0.0709 - accuracy: 0.98 - ETA: 3s - loss: 0.0706 - accuracy: 0.98 - ETA: 3s - loss: 0.0699 - accuracy: 0.98 - ETA: 3s - loss: 0.0697 - accuracy: 0.98 - ETA: 3s - loss: 0.0710 - accuracy: 0.98 - ETA: 2s - loss: 0.0706 - accuracy: 0.98 - ETA: 2s - loss: 0.0711 - accuracy: 0.98 - ETA: 2s - loss: 0.0721 - accuracy: 0.98 - ETA: 2s - loss: 0.0715 - accuracy: 0.98 - ETA: 2s - loss: 0.0715 - accuracy: 0.98 - ETA: 1s - loss: 0.0724 - accuracy: 0.98 - ETA: 1s - loss: 0.0747 - accuracy: 0.97 - ETA: 1s - loss: 0.0744 - accuracy: 0.97 - ETA: 1s - loss: 0.0737 - accuracy: 0.98 - ETA: 1s - loss: 0.0728 - accuracy: 0.98 - ETA: 0s - loss: 0.0728 - accuracy: 0.97 - ETA: 0s - loss: 0.0735 - accuracy: 0.97 - ETA: 0s - loss: 0.0730 - accuracy: 0.97 - ETA: 0s - loss: 0.0726 - accuracy: 0.97 - ETA: 0s - loss: 0.0724 - accuracy: 0.98 - 18s 280ms/step - loss: 0.0731 - accuracy: 0.9800 - val_loss: 1.3098 - val_accuracy: 0.5010\n",
      "Epoch 8/15\n",
      "63/63 [==============================] - ETA: 19s - loss: 0.0514 - accuracy: 1.000 - ETA: 15s - loss: 0.0530 - accuracy: 1.000 - ETA: 14s - loss: 0.0545 - accuracy: 1.000 - ETA: 13s - loss: 0.0499 - accuracy: 1.000 - ETA: 12s - loss: 0.0504 - accuracy: 0.993 - ETA: 12s - loss: 0.0532 - accuracy: 0.994 - ETA: 11s - loss: 0.0476 - accuracy: 0.995 - ETA: 11s - loss: 0.0466 - accuracy: 0.996 - ETA: 11s - loss: 0.0483 - accuracy: 0.996 - ETA: 10s - loss: 0.0530 - accuracy: 0.993 - ETA: 10s - loss: 0.0502 - accuracy: 0.994 - ETA: 10s - loss: 0.0514 - accuracy: 0.994 - ETA: 9s - loss: 0.0553 - accuracy: 0.992 - ETA: 9s - loss: 0.0584 - accuracy: 0.99 - ETA: 9s - loss: 0.0591 - accuracy: 0.98 - ETA: 9s - loss: 0.0605 - accuracy: 0.98 - ETA: 9s - loss: 0.0649 - accuracy: 0.98 - ETA: 8s - loss: 0.0673 - accuracy: 0.98 - ETA: 8s - loss: 0.0662 - accuracy: 0.98 - ETA: 8s - loss: 0.0674 - accuracy: 0.98 - ETA: 8s - loss: 0.0672 - accuracy: 0.98 - ETA: 8s - loss: 0.0659 - accuracy: 0.98 - ETA: 7s - loss: 0.0654 - accuracy: 0.99 - ETA: 7s - loss: 0.0638 - accuracy: 0.99 - ETA: 7s - loss: 0.0643 - accuracy: 0.98 - ETA: 7s - loss: 0.0627 - accuracy: 0.99 - ETA: 7s - loss: 0.0651 - accuracy: 0.98 - ETA: 6s - loss: 0.0648 - accuracy: 0.98 - ETA: 6s - loss: 0.0658 - accuracy: 0.98 - ETA: 6s - loss: 0.0654 - accuracy: 0.98 - ETA: 6s - loss: 0.0662 - accuracy: 0.98 - ETA: 6s - loss: 0.0654 - accuracy: 0.98 - ETA: 5s - loss: 0.0656 - accuracy: 0.98 - ETA: 5s - loss: 0.0678 - accuracy: 0.98 - ETA: 5s - loss: 0.0675 - accuracy: 0.98 - ETA: 5s - loss: 0.0669 - accuracy: 0.98 - ETA: 5s - loss: 0.0661 - accuracy: 0.98 - ETA: 4s - loss: 0.0650 - accuracy: 0.98 - ETA: 4s - loss: 0.0640 - accuracy: 0.98 - ETA: 4s - loss: 0.0637 - accuracy: 0.98 - ETA: 4s - loss: 0.0636 - accuracy: 0.98 - ETA: 4s - loss: 0.0643 - accuracy: 0.98 - ETA: 3s - loss: 0.0650 - accuracy: 0.98 - ETA: 3s - loss: 0.0649 - accuracy: 0.98 - ETA: 3s - loss: 0.0639 - accuracy: 0.98 - ETA: 3s - loss: 0.0635 - accuracy: 0.98 - ETA: 3s - loss: 0.0631 - accuracy: 0.98 - ETA: 2s - loss: 0.0629 - accuracy: 0.98 - ETA: 2s - loss: 0.0623 - accuracy: 0.98 - ETA: 2s - loss: 0.0635 - accuracy: 0.98 - ETA: 2s - loss: 0.0630 - accuracy: 0.98 - ETA: 2s - loss: 0.0632 - accuracy: 0.98 - ETA: 1s - loss: 0.0638 - accuracy: 0.98 - ETA: 1s - loss: 0.0633 - accuracy: 0.98 - ETA: 1s - loss: 0.0627 - accuracy: 0.98 - ETA: 1s - loss: 0.0624 - accuracy: 0.98 - ETA: 1s - loss: 0.0621 - accuracy: 0.98 - ETA: 0s - loss: 0.0625 - accuracy: 0.98 - ETA: 0s - loss: 0.0627 - accuracy: 0.98 - ETA: 0s - loss: 0.0625 - accuracy: 0.98 - ETA: 0s - loss: 0.0617 - accuracy: 0.98 - ETA: 0s - loss: 0.0614 - accuracy: 0.98 - 18s 281ms/step - loss: 0.0618 - accuracy: 0.9860 - val_loss: 1.1154 - val_accuracy: 0.5050\n",
      "Epoch 9/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - ETA: 19s - loss: 0.0791 - accuracy: 1.000 - ETA: 15s - loss: 0.0771 - accuracy: 1.000 - ETA: 13s - loss: 0.0689 - accuracy: 1.000 - ETA: 13s - loss: 0.0606 - accuracy: 1.000 - ETA: 12s - loss: 0.0576 - accuracy: 1.000 - ETA: 12s - loss: 0.0589 - accuracy: 0.994 - ETA: 11s - loss: 0.0647 - accuracy: 0.986 - ETA: 11s - loss: 0.0618 - accuracy: 0.984 - ETA: 11s - loss: 0.0580 - accuracy: 0.986 - ETA: 10s - loss: 0.0555 - accuracy: 0.987 - ETA: 10s - loss: 0.0530 - accuracy: 0.988 - ETA: 10s - loss: 0.0509 - accuracy: 0.989 - ETA: 10s - loss: 0.0502 - accuracy: 0.990 - ETA: 9s - loss: 0.0490 - accuracy: 0.991 - ETA: 9s - loss: 0.0489 - accuracy: 0.99 - ETA: 9s - loss: 0.0484 - accuracy: 0.99 - ETA: 9s - loss: 0.0475 - accuracy: 0.99 - ETA: 8s - loss: 0.0465 - accuracy: 0.99 - ETA: 8s - loss: 0.0503 - accuracy: 0.99 - ETA: 8s - loss: 0.0498 - accuracy: 0.99 - ETA: 8s - loss: 0.0496 - accuracy: 0.98 - ETA: 8s - loss: 0.0511 - accuracy: 0.99 - ETA: 7s - loss: 0.0546 - accuracy: 0.98 - ETA: 7s - loss: 0.0546 - accuracy: 0.98 - ETA: 7s - loss: 0.0542 - accuracy: 0.98 - ETA: 7s - loss: 0.0538 - accuracy: 0.98 - ETA: 7s - loss: 0.0526 - accuracy: 0.98 - ETA: 6s - loss: 0.0531 - accuracy: 0.98 - ETA: 6s - loss: 0.0529 - accuracy: 0.98 - ETA: 6s - loss: 0.0539 - accuracy: 0.98 - ETA: 6s - loss: 0.0527 - accuracy: 0.98 - ETA: 6s - loss: 0.0524 - accuracy: 0.98 - ETA: 5s - loss: 0.0536 - accuracy: 0.98 - ETA: 5s - loss: 0.0546 - accuracy: 0.98 - ETA: 5s - loss: 0.0552 - accuracy: 0.98 - ETA: 5s - loss: 0.0552 - accuracy: 0.98 - ETA: 5s - loss: 0.0553 - accuracy: 0.98 - ETA: 4s - loss: 0.0545 - accuracy: 0.98 - ETA: 4s - loss: 0.0542 - accuracy: 0.98 - ETA: 4s - loss: 0.0539 - accuracy: 0.98 - ETA: 4s - loss: 0.0538 - accuracy: 0.98 - ETA: 4s - loss: 0.0543 - accuracy: 0.98 - ETA: 3s - loss: 0.0539 - accuracy: 0.98 - ETA: 3s - loss: 0.0529 - accuracy: 0.98 - ETA: 3s - loss: 0.0527 - accuracy: 0.98 - ETA: 3s - loss: 0.0528 - accuracy: 0.98 - ETA: 3s - loss: 0.0525 - accuracy: 0.98 - ETA: 2s - loss: 0.0517 - accuracy: 0.98 - ETA: 2s - loss: 0.0514 - accuracy: 0.98 - ETA: 2s - loss: 0.0508 - accuracy: 0.98 - ETA: 2s - loss: 0.0504 - accuracy: 0.98 - ETA: 2s - loss: 0.0502 - accuracy: 0.98 - ETA: 1s - loss: 0.0501 - accuracy: 0.98 - ETA: 1s - loss: 0.0500 - accuracy: 0.98 - ETA: 1s - loss: 0.0504 - accuracy: 0.98 - ETA: 1s - loss: 0.0507 - accuracy: 0.98 - ETA: 1s - loss: 0.0513 - accuracy: 0.98 - ETA: 0s - loss: 0.0513 - accuracy: 0.98 - ETA: 0s - loss: 0.0512 - accuracy: 0.98 - ETA: 0s - loss: 0.0517 - accuracy: 0.98 - ETA: 0s - loss: 0.0521 - accuracy: 0.98 - ETA: 0s - loss: 0.0516 - accuracy: 0.98 - 18s 279ms/step - loss: 0.0517 - accuracy: 0.9885 - val_loss: 1.1284 - val_accuracy: 0.5060\n",
      "Epoch 10/15\n",
      "63/63 [==============================] - ETA: 19s - loss: 0.0699 - accuracy: 0.968 - ETA: 15s - loss: 0.0441 - accuracy: 0.984 - ETA: 14s - loss: 0.0414 - accuracy: 0.989 - ETA: 13s - loss: 0.0382 - accuracy: 0.992 - ETA: 12s - loss: 0.0398 - accuracy: 0.993 - ETA: 12s - loss: 0.0424 - accuracy: 0.994 - ETA: 11s - loss: 0.0389 - accuracy: 0.995 - ETA: 11s - loss: 0.0381 - accuracy: 0.996 - ETA: 11s - loss: 0.0369 - accuracy: 0.996 - ETA: 10s - loss: 0.0364 - accuracy: 0.996 - ETA: 10s - loss: 0.0354 - accuracy: 0.997 - ETA: 10s - loss: 0.0368 - accuracy: 0.997 - ETA: 10s - loss: 0.0368 - accuracy: 0.997 - ETA: 9s - loss: 0.0368 - accuracy: 0.997 - ETA: 9s - loss: 0.0366 - accuracy: 0.99 - ETA: 9s - loss: 0.0347 - accuracy: 0.99 - ETA: 9s - loss: 0.0345 - accuracy: 0.99 - ETA: 9s - loss: 0.0369 - accuracy: 0.99 - ETA: 8s - loss: 0.0393 - accuracy: 0.99 - ETA: 8s - loss: 0.0382 - accuracy: 0.99 - ETA: 8s - loss: 0.0373 - accuracy: 0.99 - ETA: 8s - loss: 0.0367 - accuracy: 0.99 - ETA: 7s - loss: 0.0376 - accuracy: 0.99 - ETA: 7s - loss: 0.0430 - accuracy: 0.99 - ETA: 7s - loss: 0.0421 - accuracy: 0.99 - ETA: 7s - loss: 0.0417 - accuracy: 0.99 - ETA: 7s - loss: 0.0435 - accuracy: 0.99 - ETA: 6s - loss: 0.0429 - accuracy: 0.99 - ETA: 6s - loss: 0.0424 - accuracy: 0.99 - ETA: 6s - loss: 0.0424 - accuracy: 0.99 - ETA: 6s - loss: 0.0423 - accuracy: 0.99 - ETA: 6s - loss: 0.0431 - accuracy: 0.99 - ETA: 5s - loss: 0.0426 - accuracy: 0.99 - ETA: 5s - loss: 0.0433 - accuracy: 0.99 - ETA: 5s - loss: 0.0428 - accuracy: 0.99 - ETA: 5s - loss: 0.0430 - accuracy: 0.99 - ETA: 5s - loss: 0.0425 - accuracy: 0.99 - ETA: 4s - loss: 0.0425 - accuracy: 0.99 - ETA: 4s - loss: 0.0420 - accuracy: 0.99 - ETA: 4s - loss: 0.0428 - accuracy: 0.99 - ETA: 4s - loss: 0.0434 - accuracy: 0.99 - ETA: 4s - loss: 0.0427 - accuracy: 0.99 - ETA: 3s - loss: 0.0435 - accuracy: 0.99 - ETA: 3s - loss: 0.0441 - accuracy: 0.99 - ETA: 3s - loss: 0.0441 - accuracy: 0.99 - ETA: 3s - loss: 0.0438 - accuracy: 0.99 - ETA: 3s - loss: 0.0435 - accuracy: 0.99 - ETA: 2s - loss: 0.0434 - accuracy: 0.99 - ETA: 2s - loss: 0.0440 - accuracy: 0.99 - ETA: 2s - loss: 0.0434 - accuracy: 0.99 - ETA: 2s - loss: 0.0436 - accuracy: 0.99 - ETA: 2s - loss: 0.0438 - accuracy: 0.99 - ETA: 1s - loss: 0.0438 - accuracy: 0.99 - ETA: 1s - loss: 0.0437 - accuracy: 0.99 - ETA: 1s - loss: 0.0437 - accuracy: 0.99 - ETA: 1s - loss: 0.0432 - accuracy: 0.99 - ETA: 1s - loss: 0.0433 - accuracy: 0.99 - ETA: 0s - loss: 0.0429 - accuracy: 0.99 - ETA: 0s - loss: 0.0427 - accuracy: 0.99 - ETA: 0s - loss: 0.0424 - accuracy: 0.99 - ETA: 0s - loss: 0.0419 - accuracy: 0.99 - ETA: 0s - loss: 0.0429 - accuracy: 0.99 - 18s 284ms/step - loss: 0.0425 - accuracy: 0.9930 - val_loss: 1.6133 - val_accuracy: 0.5000\n",
      "Epoch 11/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - ETA: 20s - loss: 0.0412 - accuracy: 1.000 - ETA: 16s - loss: 0.0490 - accuracy: 1.000 - ETA: 14s - loss: 0.0384 - accuracy: 1.000 - ETA: 13s - loss: 0.0308 - accuracy: 1.000 - ETA: 13s - loss: 0.0282 - accuracy: 1.000 - ETA: 12s - loss: 0.0271 - accuracy: 1.000 - ETA: 12s - loss: 0.0267 - accuracy: 1.000 - ETA: 12s - loss: 0.0261 - accuracy: 1.000 - ETA: 11s - loss: 0.0255 - accuracy: 1.000 - ETA: 11s - loss: 0.0253 - accuracy: 1.000 - ETA: 11s - loss: 0.0249 - accuracy: 1.000 - ETA: 10s - loss: 0.0242 - accuracy: 1.000 - ETA: 10s - loss: 0.0240 - accuracy: 1.000 - ETA: 10s - loss: 0.0239 - accuracy: 1.000 - ETA: 10s - loss: 0.0238 - accuracy: 1.000 - ETA: 9s - loss: 0.0245 - accuracy: 1.000 - ETA: 9s - loss: 0.0249 - accuracy: 1.00 - ETA: 9s - loss: 0.0244 - accuracy: 1.00 - ETA: 9s - loss: 0.0250 - accuracy: 1.00 - ETA: 8s - loss: 0.0248 - accuracy: 1.00 - ETA: 8s - loss: 0.0251 - accuracy: 1.00 - ETA: 8s - loss: 0.0251 - accuracy: 1.00 - ETA: 8s - loss: 0.0244 - accuracy: 1.00 - ETA: 7s - loss: 0.0248 - accuracy: 1.00 - ETA: 7s - loss: 0.0247 - accuracy: 1.00 - ETA: 7s - loss: 0.0251 - accuracy: 1.00 - ETA: 7s - loss: 0.0263 - accuracy: 0.99 - ETA: 7s - loss: 0.0267 - accuracy: 0.99 - ETA: 6s - loss: 0.0271 - accuracy: 0.99 - ETA: 6s - loss: 0.0277 - accuracy: 0.99 - ETA: 6s - loss: 0.0279 - accuracy: 0.99 - ETA: 6s - loss: 0.0279 - accuracy: 0.99 - ETA: 5s - loss: 0.0289 - accuracy: 0.99 - ETA: 5s - loss: 0.0293 - accuracy: 0.99 - ETA: 5s - loss: 0.0290 - accuracy: 0.99 - ETA: 5s - loss: 0.0289 - accuracy: 0.99 - ETA: 5s - loss: 0.0287 - accuracy: 0.99 - ETA: 4s - loss: 0.0286 - accuracy: 0.99 - ETA: 4s - loss: 0.0288 - accuracy: 0.99 - ETA: 4s - loss: 0.0288 - accuracy: 0.99 - ETA: 4s - loss: 0.0284 - accuracy: 0.99 - ETA: 4s - loss: 0.0290 - accuracy: 0.99 - ETA: 3s - loss: 0.0314 - accuracy: 0.99 - ETA: 3s - loss: 0.0314 - accuracy: 0.99 - ETA: 3s - loss: 0.0318 - accuracy: 0.99 - ETA: 3s - loss: 0.0324 - accuracy: 0.99 - ETA: 3s - loss: 0.0331 - accuracy: 0.99 - ETA: 2s - loss: 0.0337 - accuracy: 0.99 - ETA: 2s - loss: 0.0333 - accuracy: 0.99 - ETA: 2s - loss: 0.0333 - accuracy: 0.99 - ETA: 2s - loss: 0.0330 - accuracy: 0.99 - ETA: 2s - loss: 0.0330 - accuracy: 0.99 - ETA: 1s - loss: 0.0328 - accuracy: 0.99 - ETA: 1s - loss: 0.0328 - accuracy: 0.99 - ETA: 1s - loss: 0.0332 - accuracy: 0.99 - ETA: 1s - loss: 0.0328 - accuracy: 0.99 - ETA: 1s - loss: 0.0327 - accuracy: 0.99 - ETA: 0s - loss: 0.0326 - accuracy: 0.99 - ETA: 0s - loss: 0.0325 - accuracy: 0.99 - ETA: 0s - loss: 0.0328 - accuracy: 0.99 - ETA: 0s - loss: 0.0328 - accuracy: 0.99 - ETA: 0s - loss: 0.0341 - accuracy: 0.99 - 18s 286ms/step - loss: 0.0346 - accuracy: 0.9940 - val_loss: 1.6462 - val_accuracy: 0.5010\n",
      "Epoch 12/15\n",
      "63/63 [==============================] - ETA: 21s - loss: 0.0194 - accuracy: 1.000 - ETA: 16s - loss: 0.0208 - accuracy: 1.000 - ETA: 15s - loss: 0.0267 - accuracy: 1.000 - ETA: 14s - loss: 0.0250 - accuracy: 1.000 - ETA: 13s - loss: 0.0224 - accuracy: 1.000 - ETA: 13s - loss: 0.0268 - accuracy: 1.000 - ETA: 12s - loss: 0.0251 - accuracy: 1.000 - ETA: 12s - loss: 0.0246 - accuracy: 1.000 - ETA: 12s - loss: 0.0249 - accuracy: 1.000 - ETA: 11s - loss: 0.0260 - accuracy: 1.000 - ETA: 11s - loss: 0.0257 - accuracy: 1.000 - ETA: 11s - loss: 0.0260 - accuracy: 1.000 - ETA: 11s - loss: 0.0260 - accuracy: 1.000 - ETA: 10s - loss: 0.0255 - accuracy: 1.000 - ETA: 10s - loss: 0.0263 - accuracy: 1.000 - ETA: 10s - loss: 0.0255 - accuracy: 1.000 - ETA: 9s - loss: 0.0262 - accuracy: 1.000 - ETA: 9s - loss: 0.0259 - accuracy: 1.00 - ETA: 9s - loss: 0.0271 - accuracy: 1.00 - ETA: 9s - loss: 0.0266 - accuracy: 1.00 - ETA: 9s - loss: 0.0264 - accuracy: 1.00 - ETA: 8s - loss: 0.0257 - accuracy: 1.00 - ETA: 8s - loss: 0.0254 - accuracy: 1.00 - ETA: 8s - loss: 0.0249 - accuracy: 1.00 - ETA: 8s - loss: 0.0253 - accuracy: 1.00 - ETA: 7s - loss: 0.0254 - accuracy: 1.00 - ETA: 7s - loss: 0.0265 - accuracy: 0.99 - ETA: 7s - loss: 0.0259 - accuracy: 0.99 - ETA: 7s - loss: 0.0258 - accuracy: 0.99 - ETA: 6s - loss: 0.0258 - accuracy: 0.99 - ETA: 6s - loss: 0.0254 - accuracy: 0.99 - ETA: 6s - loss: 0.0256 - accuracy: 0.99 - ETA: 6s - loss: 0.0256 - accuracy: 0.99 - ETA: 5s - loss: 0.0254 - accuracy: 0.99 - ETA: 5s - loss: 0.0247 - accuracy: 0.99 - ETA: 5s - loss: 0.0249 - accuracy: 0.99 - ETA: 5s - loss: 0.0249 - accuracy: 0.99 - ETA: 5s - loss: 0.0245 - accuracy: 0.99 - ETA: 4s - loss: 0.0242 - accuracy: 0.99 - ETA: 4s - loss: 0.0245 - accuracy: 0.99 - ETA: 4s - loss: 0.0242 - accuracy: 0.99 - ETA: 4s - loss: 0.0240 - accuracy: 0.99 - ETA: 4s - loss: 0.0245 - accuracy: 0.99 - ETA: 3s - loss: 0.0243 - accuracy: 0.99 - ETA: 3s - loss: 0.0245 - accuracy: 0.99 - ETA: 3s - loss: 0.0243 - accuracy: 0.99 - ETA: 3s - loss: 0.0246 - accuracy: 0.99 - ETA: 3s - loss: 0.0245 - accuracy: 0.99 - ETA: 2s - loss: 0.0244 - accuracy: 0.99 - ETA: 2s - loss: 0.0243 - accuracy: 0.99 - ETA: 2s - loss: 0.0244 - accuracy: 0.99 - ETA: 2s - loss: 0.0245 - accuracy: 0.99 - ETA: 2s - loss: 0.0244 - accuracy: 0.99 - ETA: 1s - loss: 0.0246 - accuracy: 0.99 - ETA: 1s - loss: 0.0246 - accuracy: 0.99 - ETA: 1s - loss: 0.0252 - accuracy: 0.99 - ETA: 1s - loss: 0.0250 - accuracy: 0.99 - ETA: 1s - loss: 0.0250 - accuracy: 0.99 - ETA: 0s - loss: 0.0248 - accuracy: 0.99 - ETA: 0s - loss: 0.0246 - accuracy: 0.99 - ETA: 0s - loss: 0.0251 - accuracy: 0.99 - ETA: 0s - loss: 0.0254 - accuracy: 0.99 - 18s 290ms/step - loss: 0.0257 - accuracy: 0.9970 - val_loss: 1.7214 - val_accuracy: 0.5010\n",
      "Epoch 13/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - ETA: 19s - loss: 0.0173 - accuracy: 1.000 - ETA: 15s - loss: 0.0125 - accuracy: 1.000 - ETA: 14s - loss: 0.0159 - accuracy: 1.000 - ETA: 13s - loss: 0.0183 - accuracy: 1.000 - ETA: 13s - loss: 0.0192 - accuracy: 1.000 - ETA: 12s - loss: 0.0206 - accuracy: 1.000 - ETA: 12s - loss: 0.0199 - accuracy: 1.000 - ETA: 11s - loss: 0.0250 - accuracy: 1.000 - ETA: 11s - loss: 0.0239 - accuracy: 1.000 - ETA: 11s - loss: 0.0233 - accuracy: 1.000 - ETA: 11s - loss: 0.0243 - accuracy: 1.000 - ETA: 10s - loss: 0.0235 - accuracy: 1.000 - ETA: 10s - loss: 0.0232 - accuracy: 1.000 - ETA: 10s - loss: 0.0224 - accuracy: 1.000 - ETA: 9s - loss: 0.0219 - accuracy: 1.000 - ETA: 9s - loss: 0.0222 - accuracy: 1.00 - ETA: 9s - loss: 0.0217 - accuracy: 1.00 - ETA: 9s - loss: 0.0208 - accuracy: 1.00 - ETA: 8s - loss: 0.0207 - accuracy: 1.00 - ETA: 8s - loss: 0.0201 - accuracy: 1.00 - ETA: 8s - loss: 0.0210 - accuracy: 1.00 - ETA: 8s - loss: 0.0207 - accuracy: 1.00 - ETA: 8s - loss: 0.0204 - accuracy: 1.00 - ETA: 7s - loss: 0.0202 - accuracy: 1.00 - ETA: 7s - loss: 0.0204 - accuracy: 1.00 - ETA: 7s - loss: 0.0202 - accuracy: 1.00 - ETA: 7s - loss: 0.0204 - accuracy: 1.00 - ETA: 7s - loss: 0.0217 - accuracy: 0.99 - ETA: 6s - loss: 0.0215 - accuracy: 0.99 - ETA: 6s - loss: 0.0213 - accuracy: 0.99 - ETA: 6s - loss: 0.0215 - accuracy: 0.99 - ETA: 6s - loss: 0.0212 - accuracy: 0.99 - ETA: 6s - loss: 0.0212 - accuracy: 0.99 - ETA: 5s - loss: 0.0210 - accuracy: 0.99 - ETA: 5s - loss: 0.0207 - accuracy: 0.99 - ETA: 5s - loss: 0.0205 - accuracy: 0.99 - ETA: 5s - loss: 0.0201 - accuracy: 0.99 - ETA: 5s - loss: 0.0199 - accuracy: 0.99 - ETA: 4s - loss: 0.0203 - accuracy: 0.99 - ETA: 4s - loss: 0.0203 - accuracy: 0.99 - ETA: 4s - loss: 0.0212 - accuracy: 0.99 - ETA: 4s - loss: 0.0219 - accuracy: 0.99 - ETA: 4s - loss: 0.0219 - accuracy: 0.99 - ETA: 3s - loss: 0.0217 - accuracy: 0.99 - ETA: 3s - loss: 0.0217 - accuracy: 0.99 - ETA: 3s - loss: 0.0213 - accuracy: 0.99 - ETA: 3s - loss: 0.0214 - accuracy: 0.99 - ETA: 3s - loss: 0.0217 - accuracy: 0.99 - ETA: 2s - loss: 0.0224 - accuracy: 0.99 - ETA: 2s - loss: 0.0222 - accuracy: 0.99 - ETA: 2s - loss: 0.0222 - accuracy: 0.99 - ETA: 2s - loss: 0.0225 - accuracy: 0.99 - ETA: 2s - loss: 0.0228 - accuracy: 0.99 - ETA: 1s - loss: 0.0234 - accuracy: 0.99 - ETA: 1s - loss: 0.0232 - accuracy: 0.99 - ETA: 1s - loss: 0.0229 - accuracy: 0.99 - ETA: 1s - loss: 0.0229 - accuracy: 0.99 - ETA: 1s - loss: 0.0228 - accuracy: 0.99 - ETA: 0s - loss: 0.0226 - accuracy: 0.99 - ETA: 0s - loss: 0.0225 - accuracy: 0.99 - ETA: 0s - loss: 0.0225 - accuracy: 0.99 - ETA: 0s - loss: 0.0223 - accuracy: 0.99 - 18s 292ms/step - loss: 0.0220 - accuracy: 0.9980 - val_loss: 1.6338 - val_accuracy: 0.5030\n",
      "Epoch 14/15\n",
      "63/63 [==============================] - ETA: 21s - loss: 0.0152 - accuracy: 1.000 - ETA: 16s - loss: 0.0147 - accuracy: 1.000 - ETA: 14s - loss: 0.0144 - accuracy: 1.000 - ETA: 13s - loss: 0.0145 - accuracy: 1.000 - ETA: 13s - loss: 0.0145 - accuracy: 1.000 - ETA: 12s - loss: 0.0135 - accuracy: 1.000 - ETA: 12s - loss: 0.0130 - accuracy: 1.000 - ETA: 12s - loss: 0.0135 - accuracy: 1.000 - ETA: 11s - loss: 0.0132 - accuracy: 1.000 - ETA: 11s - loss: 0.0133 - accuracy: 1.000 - ETA: 11s - loss: 0.0161 - accuracy: 1.000 - ETA: 10s - loss: 0.0161 - accuracy: 1.000 - ETA: 10s - loss: 0.0157 - accuracy: 1.000 - ETA: 10s - loss: 0.0164 - accuracy: 1.000 - ETA: 9s - loss: 0.0185 - accuracy: 1.000 - ETA: 9s - loss: 0.0196 - accuracy: 1.00 - ETA: 9s - loss: 0.0210 - accuracy: 1.00 - ETA: 9s - loss: 0.0204 - accuracy: 1.00 - ETA: 8s - loss: 0.0204 - accuracy: 1.00 - ETA: 8s - loss: 0.0205 - accuracy: 1.00 - ETA: 8s - loss: 0.0201 - accuracy: 1.00 - ETA: 8s - loss: 0.0196 - accuracy: 1.00 - ETA: 8s - loss: 0.0190 - accuracy: 1.00 - ETA: 7s - loss: 0.0187 - accuracy: 1.00 - ETA: 7s - loss: 0.0181 - accuracy: 1.00 - ETA: 7s - loss: 0.0178 - accuracy: 1.00 - ETA: 7s - loss: 0.0188 - accuracy: 1.00 - ETA: 6s - loss: 0.0186 - accuracy: 1.00 - ETA: 6s - loss: 0.0184 - accuracy: 1.00 - ETA: 6s - loss: 0.0182 - accuracy: 1.00 - ETA: 6s - loss: 0.0182 - accuracy: 1.00 - ETA: 6s - loss: 0.0183 - accuracy: 1.00 - ETA: 5s - loss: 0.0180 - accuracy: 1.00 - ETA: 5s - loss: 0.0179 - accuracy: 1.00 - ETA: 5s - loss: 0.0179 - accuracy: 1.00 - ETA: 5s - loss: 0.0175 - accuracy: 1.00 - ETA: 5s - loss: 0.0175 - accuracy: 1.00 - ETA: 4s - loss: 0.0174 - accuracy: 1.00 - ETA: 4s - loss: 0.0171 - accuracy: 1.00 - ETA: 4s - loss: 0.0171 - accuracy: 1.00 - ETA: 4s - loss: 0.0169 - accuracy: 1.00 - ETA: 4s - loss: 0.0169 - accuracy: 1.00 - ETA: 3s - loss: 0.0171 - accuracy: 1.00 - ETA: 3s - loss: 0.0170 - accuracy: 1.00 - ETA: 3s - loss: 0.0176 - accuracy: 1.00 - ETA: 3s - loss: 0.0175 - accuracy: 1.00 - ETA: 3s - loss: 0.0177 - accuracy: 1.00 - ETA: 2s - loss: 0.0175 - accuracy: 1.00 - ETA: 2s - loss: 0.0173 - accuracy: 1.00 - ETA: 2s - loss: 0.0171 - accuracy: 1.00 - ETA: 2s - loss: 0.0170 - accuracy: 1.00 - ETA: 2s - loss: 0.0169 - accuracy: 1.00 - ETA: 1s - loss: 0.0170 - accuracy: 1.00 - ETA: 1s - loss: 0.0174 - accuracy: 1.00 - ETA: 1s - loss: 0.0172 - accuracy: 1.00 - ETA: 1s - loss: 0.0171 - accuracy: 1.00 - ETA: 1s - loss: 0.0173 - accuracy: 1.00 - ETA: 1s - loss: 0.0176 - accuracy: 1.00 - ETA: 0s - loss: 0.0189 - accuracy: 0.99 - ETA: 0s - loss: 0.0188 - accuracy: 0.99 - ETA: 0s - loss: 0.0185 - accuracy: 0.99 - ETA: 0s - loss: 0.0183 - accuracy: 0.99 - 18s 290ms/step - loss: 0.0183 - accuracy: 0.9990 - val_loss: 2.0967 - val_accuracy: 0.5000\n",
      "Epoch 15/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - ETA: 29s - loss: 0.0044 - accuracy: 1.000 - ETA: 22s - loss: 0.0091 - accuracy: 1.000 - ETA: 19s - loss: 0.0115 - accuracy: 1.000 - ETA: 18s - loss: 0.0099 - accuracy: 1.000 - ETA: 16s - loss: 0.0095 - accuracy: 1.000 - ETA: 16s - loss: 0.0096 - accuracy: 1.000 - ETA: 15s - loss: 0.0100 - accuracy: 1.000 - ETA: 14s - loss: 0.0101 - accuracy: 1.000 - ETA: 14s - loss: 0.0104 - accuracy: 1.000 - ETA: 13s - loss: 0.0100 - accuracy: 1.000 - ETA: 13s - loss: 0.0094 - accuracy: 1.000 - ETA: 12s - loss: 0.0091 - accuracy: 1.000 - ETA: 12s - loss: 0.0109 - accuracy: 1.000 - ETA: 12s - loss: 0.0109 - accuracy: 1.000 - ETA: 11s - loss: 0.0108 - accuracy: 1.000 - ETA: 11s - loss: 0.0106 - accuracy: 1.000 - ETA: 11s - loss: 0.0103 - accuracy: 1.000 - ETA: 10s - loss: 0.0104 - accuracy: 1.000 - ETA: 10s - loss: 0.0105 - accuracy: 1.000 - ETA: 10s - loss: 0.0108 - accuracy: 1.000 - ETA: 9s - loss: 0.0108 - accuracy: 1.000 - ETA: 9s - loss: 0.0106 - accuracy: 1.00 - ETA: 9s - loss: 0.0107 - accuracy: 1.00 - ETA: 8s - loss: 0.0105 - accuracy: 1.00 - ETA: 8s - loss: 0.0107 - accuracy: 1.00 - ETA: 8s - loss: 0.0106 - accuracy: 1.00 - ETA: 8s - loss: 0.0106 - accuracy: 1.00 - ETA: 7s - loss: 0.0106 - accuracy: 1.00 - ETA: 7s - loss: 0.0105 - accuracy: 1.00 - ETA: 7s - loss: 0.0105 - accuracy: 1.00 - ETA: 7s - loss: 0.0105 - accuracy: 1.00 - ETA: 7s - loss: 0.0103 - accuracy: 1.00 - ETA: 6s - loss: 0.0102 - accuracy: 1.00 - ETA: 6s - loss: 0.0108 - accuracy: 1.00 - ETA: 6s - loss: 0.0110 - accuracy: 1.00 - ETA: 6s - loss: 0.0108 - accuracy: 1.00 - ETA: 5s - loss: 0.0113 - accuracy: 1.00 - ETA: 5s - loss: 0.0112 - accuracy: 1.00 - ETA: 5s - loss: 0.0114 - accuracy: 1.00 - ETA: 5s - loss: 0.0113 - accuracy: 1.00 - ETA: 4s - loss: 0.0115 - accuracy: 1.00 - ETA: 4s - loss: 0.0114 - accuracy: 1.00 - ETA: 4s - loss: 0.0116 - accuracy: 1.00 - ETA: 4s - loss: 0.0116 - accuracy: 1.00 - ETA: 4s - loss: 0.0115 - accuracy: 1.00 - ETA: 3s - loss: 0.0121 - accuracy: 0.99 - ETA: 3s - loss: 0.0124 - accuracy: 0.99 - ETA: 3s - loss: 0.0123 - accuracy: 0.99 - ETA: 3s - loss: 0.0123 - accuracy: 0.99 - ETA: 2s - loss: 0.0122 - accuracy: 0.99 - ETA: 2s - loss: 0.0122 - accuracy: 0.99 - ETA: 2s - loss: 0.0123 - accuracy: 0.99 - ETA: 2s - loss: 0.0122 - accuracy: 0.99 - ETA: 2s - loss: 0.0127 - accuracy: 0.99 - ETA: 1s - loss: 0.0130 - accuracy: 0.99 - ETA: 1s - loss: 0.0131 - accuracy: 0.99 - ETA: 1s - loss: 0.0132 - accuracy: 0.99 - ETA: 1s - loss: 0.0131 - accuracy: 0.99 - ETA: 0s - loss: 0.0130 - accuracy: 0.99 - ETA: 0s - loss: 0.0129 - accuracy: 0.99 - ETA: 0s - loss: 0.0131 - accuracy: 0.99 - ETA: 0s - loss: 0.0130 - accuracy: 0.99 - 20s 311ms/step - loss: 0.0131 - accuracy: 0.9990 - val_loss: 2.3717 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a33a28cf08>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_generator, epochs=5,validation_data=validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate_generator(validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.3717147558927536, Accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "print('Loss: {}, Accuracy: {}'.format(loss, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers in the base_model : 155\n"
     ]
    }
   ],
   "source": [
    "print('Number of layers in the base_model : {}'.format(len(base_model.layers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_at = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=0.0001), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 63 steps, validate for 32 steps\n",
      "Epoch 1/5\n",
      "63/63 [==============================] - ETA: 19s - loss: 0.0114 - accuracy: 1.000 - ETA: 15s - loss: 0.0096 - accuracy: 1.000 - ETA: 14s - loss: 0.0077 - accuracy: 1.000 - ETA: 13s - loss: 0.0103 - accuracy: 1.000 - ETA: 12s - loss: 0.0096 - accuracy: 1.000 - ETA: 12s - loss: 0.0090 - accuracy: 1.000 - ETA: 11s - loss: 0.0080 - accuracy: 1.000 - ETA: 11s - loss: 0.0084 - accuracy: 1.000 - ETA: 11s - loss: 0.0081 - accuracy: 1.000 - ETA: 10s - loss: 0.0082 - accuracy: 1.000 - ETA: 10s - loss: 0.0077 - accuracy: 1.000 - ETA: 10s - loss: 0.0078 - accuracy: 1.000 - ETA: 10s - loss: 0.0082 - accuracy: 1.000 - ETA: 9s - loss: 0.0090 - accuracy: 1.000 - ETA: 9s - loss: 0.0090 - accuracy: 1.00 - ETA: 9s - loss: 0.0089 - accuracy: 1.00 - ETA: 9s - loss: 0.0101 - accuracy: 1.00 - ETA: 9s - loss: 0.0108 - accuracy: 1.00 - ETA: 8s - loss: 0.0106 - accuracy: 1.00 - ETA: 8s - loss: 0.0106 - accuracy: 1.00 - ETA: 8s - loss: 0.0103 - accuracy: 1.00 - ETA: 8s - loss: 0.0102 - accuracy: 1.00 - ETA: 7s - loss: 0.0104 - accuracy: 1.00 - ETA: 7s - loss: 0.0105 - accuracy: 1.00 - ETA: 7s - loss: 0.0104 - accuracy: 1.00 - ETA: 7s - loss: 0.0104 - accuracy: 1.00 - ETA: 7s - loss: 0.0102 - accuracy: 1.00 - ETA: 6s - loss: 0.0100 - accuracy: 1.00 - ETA: 6s - loss: 0.0100 - accuracy: 1.00 - ETA: 6s - loss: 0.0101 - accuracy: 1.00 - ETA: 6s - loss: 0.0099 - accuracy: 1.00 - ETA: 6s - loss: 0.0098 - accuracy: 1.00 - ETA: 5s - loss: 0.0096 - accuracy: 1.00 - ETA: 5s - loss: 0.0097 - accuracy: 1.00 - ETA: 5s - loss: 0.0097 - accuracy: 1.00 - ETA: 5s - loss: 0.0105 - accuracy: 1.00 - ETA: 5s - loss: 0.0104 - accuracy: 1.00 - ETA: 4s - loss: 0.0103 - accuracy: 1.00 - ETA: 4s - loss: 0.0105 - accuracy: 1.00 - ETA: 4s - loss: 0.0104 - accuracy: 1.00 - ETA: 4s - loss: 0.0104 - accuracy: 1.00 - ETA: 4s - loss: 0.0105 - accuracy: 1.00 - ETA: 3s - loss: 0.0104 - accuracy: 1.00 - ETA: 3s - loss: 0.0104 - accuracy: 1.00 - ETA: 3s - loss: 0.0103 - accuracy: 1.00 - ETA: 3s - loss: 0.0101 - accuracy: 1.00 - ETA: 3s - loss: 0.0101 - accuracy: 1.00 - ETA: 2s - loss: 0.0104 - accuracy: 1.00 - ETA: 2s - loss: 0.0103 - accuracy: 1.00 - ETA: 2s - loss: 0.0104 - accuracy: 1.00 - ETA: 2s - loss: 0.0105 - accuracy: 1.00 - ETA: 2s - loss: 0.0107 - accuracy: 1.00 - ETA: 1s - loss: 0.0116 - accuracy: 1.00 - ETA: 1s - loss: 0.0114 - accuracy: 1.00 - ETA: 1s - loss: 0.0115 - accuracy: 1.00 - ETA: 1s - loss: 0.0116 - accuracy: 1.00 - ETA: 1s - loss: 0.0115 - accuracy: 1.00 - ETA: 0s - loss: 0.0115 - accuracy: 1.00 - ETA: 0s - loss: 0.0114 - accuracy: 1.00 - ETA: 0s - loss: 0.0113 - accuracy: 1.00 - ETA: 0s - loss: 0.0113 - accuracy: 1.00 - ETA: 0s - loss: 0.0112 - accuracy: 1.00 - 18s 280ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 2.4541 - val_accuracy: 0.5000\n",
      "Epoch 2/5\n",
      "63/63 [==============================] - ETA: 20s - loss: 0.0064 - accuracy: 1.000 - ETA: 16s - loss: 0.0092 - accuracy: 1.000 - ETA: 14s - loss: 0.0087 - accuracy: 1.000 - ETA: 13s - loss: 0.0104 - accuracy: 1.000 - ETA: 12s - loss: 0.0089 - accuracy: 1.000 - ETA: 11s - loss: 0.0093 - accuracy: 1.000 - ETA: 11s - loss: 0.0101 - accuracy: 1.000 - ETA: 11s - loss: 0.0096 - accuracy: 1.000 - ETA: 10s - loss: 0.0093 - accuracy: 1.000 - ETA: 10s - loss: 0.0098 - accuracy: 1.000 - ETA: 10s - loss: 0.0092 - accuracy: 1.000 - ETA: 10s - loss: 0.0093 - accuracy: 1.000 - ETA: 9s - loss: 0.0087 - accuracy: 1.000 - ETA: 9s - loss: 0.0091 - accuracy: 1.00 - ETA: 9s - loss: 0.0086 - accuracy: 1.00 - ETA: 9s - loss: 0.0085 - accuracy: 1.00 - ETA: 9s - loss: 0.0083 - accuracy: 1.00 - ETA: 8s - loss: 0.0081 - accuracy: 1.00 - ETA: 8s - loss: 0.0080 - accuracy: 1.00 - ETA: 8s - loss: 0.0085 - accuracy: 1.00 - ETA: 8s - loss: 0.0084 - accuracy: 1.00 - ETA: 8s - loss: 0.0083 - accuracy: 1.00 - ETA: 7s - loss: 0.0084 - accuracy: 1.00 - ETA: 7s - loss: 0.0083 - accuracy: 1.00 - ETA: 7s - loss: 0.0081 - accuracy: 1.00 - ETA: 7s - loss: 0.0080 - accuracy: 1.00 - ETA: 7s - loss: 0.0079 - accuracy: 1.00 - ETA: 6s - loss: 0.0080 - accuracy: 1.00 - ETA: 6s - loss: 0.0082 - accuracy: 1.00 - ETA: 6s - loss: 0.0084 - accuracy: 1.00 - ETA: 6s - loss: 0.0082 - accuracy: 1.00 - ETA: 6s - loss: 0.0083 - accuracy: 1.00 - ETA: 5s - loss: 0.0085 - accuracy: 1.00 - ETA: 5s - loss: 0.0084 - accuracy: 1.00 - ETA: 5s - loss: 0.0082 - accuracy: 1.00 - ETA: 5s - loss: 0.0082 - accuracy: 1.00 - ETA: 5s - loss: 0.0081 - accuracy: 1.00 - ETA: 4s - loss: 0.0085 - accuracy: 1.00 - ETA: 4s - loss: 0.0084 - accuracy: 1.00 - ETA: 4s - loss: 0.0084 - accuracy: 1.00 - ETA: 4s - loss: 0.0086 - accuracy: 1.00 - ETA: 4s - loss: 0.0085 - accuracy: 1.00 - ETA: 3s - loss: 0.0086 - accuracy: 1.00 - ETA: 3s - loss: 0.0086 - accuracy: 1.00 - ETA: 3s - loss: 0.0087 - accuracy: 1.00 - ETA: 3s - loss: 0.0089 - accuracy: 1.00 - ETA: 3s - loss: 0.0088 - accuracy: 1.00 - ETA: 2s - loss: 0.0088 - accuracy: 1.00 - ETA: 2s - loss: 0.0088 - accuracy: 1.00 - ETA: 2s - loss: 0.0088 - accuracy: 1.00 - ETA: 2s - loss: 0.0087 - accuracy: 1.00 - ETA: 2s - loss: 0.0087 - accuracy: 1.00 - ETA: 1s - loss: 0.0085 - accuracy: 1.00 - ETA: 1s - loss: 0.0085 - accuracy: 1.00 - ETA: 1s - loss: 0.0086 - accuracy: 1.00 - ETA: 1s - loss: 0.0085 - accuracy: 1.00 - ETA: 1s - loss: 0.0084 - accuracy: 1.00 - ETA: 0s - loss: 0.0084 - accuracy: 1.00 - ETA: 0s - loss: 0.0084 - accuracy: 1.00 - ETA: 0s - loss: 0.0084 - accuracy: 1.00 - ETA: 0s - loss: 0.0084 - accuracy: 1.00 - ETA: 0s - loss: 0.0083 - accuracy: 1.00 - 18s 282ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 2.8844 - val_accuracy: 0.5000\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - ETA: 18s - loss: 0.0034 - accuracy: 1.000 - ETA: 15s - loss: 0.0044 - accuracy: 1.000 - ETA: 14s - loss: 0.0044 - accuracy: 1.000 - ETA: 11s - loss: 0.0039 - accuracy: 1.000 - ETA: 11s - loss: 0.0047 - accuracy: 1.000 - ETA: 11s - loss: 0.0042 - accuracy: 1.000 - ETA: 11s - loss: 0.0041 - accuracy: 1.000 - ETA: 11s - loss: 0.0040 - accuracy: 1.000 - ETA: 10s - loss: 0.0040 - accuracy: 1.000 - ETA: 10s - loss: 0.0040 - accuracy: 1.000 - ETA: 10s - loss: 0.0040 - accuracy: 1.000 - ETA: 10s - loss: 0.0043 - accuracy: 1.000 - ETA: 9s - loss: 0.0043 - accuracy: 1.000 - ETA: 9s - loss: 0.0042 - accuracy: 1.00 - ETA: 9s - loss: 0.0050 - accuracy: 1.00 - ETA: 9s - loss: 0.0049 - accuracy: 1.00 - ETA: 9s - loss: 0.0057 - accuracy: 1.00 - ETA: 8s - loss: 0.0056 - accuracy: 1.00 - ETA: 8s - loss: 0.0056 - accuracy: 1.00 - ETA: 8s - loss: 0.0058 - accuracy: 1.00 - ETA: 8s - loss: 0.0059 - accuracy: 1.00 - ETA: 7s - loss: 0.0058 - accuracy: 1.00 - ETA: 7s - loss: 0.0064 - accuracy: 1.00 - ETA: 7s - loss: 0.0067 - accuracy: 1.00 - ETA: 7s - loss: 0.0066 - accuracy: 1.00 - ETA: 7s - loss: 0.0066 - accuracy: 1.00 - ETA: 7s - loss: 0.0064 - accuracy: 1.00 - ETA: 6s - loss: 0.0064 - accuracy: 1.00 - ETA: 6s - loss: 0.0063 - accuracy: 1.00 - ETA: 6s - loss: 0.0065 - accuracy: 1.00 - ETA: 6s - loss: 0.0064 - accuracy: 1.00 - ETA: 6s - loss: 0.0064 - accuracy: 1.00 - ETA: 5s - loss: 0.0065 - accuracy: 1.00 - ETA: 5s - loss: 0.0065 - accuracy: 1.00 - ETA: 5s - loss: 0.0064 - accuracy: 1.00 - ETA: 5s - loss: 0.0064 - accuracy: 1.00 - ETA: 5s - loss: 0.0063 - accuracy: 1.00 - ETA: 4s - loss: 0.0062 - accuracy: 1.00 - ETA: 4s - loss: 0.0061 - accuracy: 1.00 - ETA: 4s - loss: 0.0063 - accuracy: 1.00 - ETA: 4s - loss: 0.0062 - accuracy: 1.00 - ETA: 4s - loss: 0.0062 - accuracy: 1.00 - ETA: 3s - loss: 0.0061 - accuracy: 1.00 - ETA: 3s - loss: 0.0063 - accuracy: 1.00 - ETA: 3s - loss: 0.0062 - accuracy: 1.00 - ETA: 3s - loss: 0.0062 - accuracy: 1.00 - ETA: 3s - loss: 0.0064 - accuracy: 1.00 - ETA: 2s - loss: 0.0063 - accuracy: 1.00 - ETA: 2s - loss: 0.0063 - accuracy: 1.00 - ETA: 2s - loss: 0.0062 - accuracy: 1.00 - ETA: 2s - loss: 0.0061 - accuracy: 1.00 - ETA: 2s - loss: 0.0060 - accuracy: 1.00 - ETA: 1s - loss: 0.0062 - accuracy: 1.00 - ETA: 1s - loss: 0.0064 - accuracy: 1.00 - ETA: 1s - loss: 0.0064 - accuracy: 1.00 - ETA: 1s - loss: 0.0065 - accuracy: 1.00 - ETA: 1s - loss: 0.0064 - accuracy: 1.00 - ETA: 0s - loss: 0.0063 - accuracy: 1.00 - ETA: 0s - loss: 0.0063 - accuracy: 1.00 - ETA: 0s - loss: 0.0063 - accuracy: 1.00 - ETA: 0s - loss: 0.0063 - accuracy: 1.00 - ETA: 0s - loss: 0.0063 - accuracy: 1.00 - 18s 285ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 2.8843 - val_accuracy: 0.5000\n",
      "Epoch 4/5\n",
      "63/63 [==============================] - ETA: 19s - loss: 0.0055 - accuracy: 1.000 - ETA: 15s - loss: 0.0044 - accuracy: 1.000 - ETA: 14s - loss: 0.0034 - accuracy: 1.000 - ETA: 13s - loss: 0.0034 - accuracy: 1.000 - ETA: 12s - loss: 0.0033 - accuracy: 1.000 - ETA: 12s - loss: 0.0034 - accuracy: 1.000 - ETA: 12s - loss: 0.0036 - accuracy: 1.000 - ETA: 11s - loss: 0.0038 - accuracy: 1.000 - ETA: 11s - loss: 0.0043 - accuracy: 1.000 - ETA: 11s - loss: 0.0040 - accuracy: 1.000 - ETA: 10s - loss: 0.0042 - accuracy: 1.000 - ETA: 10s - loss: 0.0041 - accuracy: 1.000 - ETA: 10s - loss: 0.0040 - accuracy: 1.000 - ETA: 10s - loss: 0.0046 - accuracy: 1.000 - ETA: 9s - loss: 0.0046 - accuracy: 1.000 - ETA: 9s - loss: 0.0046 - accuracy: 1.00 - ETA: 9s - loss: 0.0044 - accuracy: 1.00 - ETA: 9s - loss: 0.0043 - accuracy: 1.00 - ETA: 8s - loss: 0.0047 - accuracy: 1.00 - ETA: 8s - loss: 0.0047 - accuracy: 1.00 - ETA: 8s - loss: 0.0050 - accuracy: 1.00 - ETA: 8s - loss: 0.0054 - accuracy: 1.00 - ETA: 8s - loss: 0.0053 - accuracy: 1.00 - ETA: 7s - loss: 0.0052 - accuracy: 1.00 - ETA: 7s - loss: 0.0051 - accuracy: 1.00 - ETA: 7s - loss: 0.0049 - accuracy: 1.00 - ETA: 7s - loss: 0.0049 - accuracy: 1.00 - ETA: 6s - loss: 0.0051 - accuracy: 1.00 - ETA: 6s - loss: 0.0050 - accuracy: 1.00 - ETA: 6s - loss: 0.0049 - accuracy: 1.00 - ETA: 6s - loss: 0.0048 - accuracy: 1.00 - ETA: 6s - loss: 0.0048 - accuracy: 1.00 - ETA: 5s - loss: 0.0048 - accuracy: 1.00 - ETA: 5s - loss: 0.0047 - accuracy: 1.00 - ETA: 5s - loss: 0.0047 - accuracy: 1.00 - ETA: 5s - loss: 0.0046 - accuracy: 1.00 - ETA: 5s - loss: 0.0046 - accuracy: 1.00 - ETA: 4s - loss: 0.0045 - accuracy: 1.00 - ETA: 4s - loss: 0.0045 - accuracy: 1.00 - ETA: 4s - loss: 0.0045 - accuracy: 1.00 - ETA: 4s - loss: 0.0045 - accuracy: 1.00 - ETA: 4s - loss: 0.0044 - accuracy: 1.00 - ETA: 3s - loss: 0.0046 - accuracy: 1.00 - ETA: 3s - loss: 0.0045 - accuracy: 1.00 - ETA: 3s - loss: 0.0045 - accuracy: 1.00 - ETA: 3s - loss: 0.0045 - accuracy: 1.00 - ETA: 3s - loss: 0.0045 - accuracy: 1.00 - ETA: 2s - loss: 0.0045 - accuracy: 1.00 - ETA: 2s - loss: 0.0045 - accuracy: 1.00 - ETA: 2s - loss: 0.0044 - accuracy: 1.00 - ETA: 2s - loss: 0.0044 - accuracy: 1.00 - ETA: 2s - loss: 0.0043 - accuracy: 1.00 - ETA: 1s - loss: 0.0047 - accuracy: 1.00 - ETA: 1s - loss: 0.0046 - accuracy: 1.00 - ETA: 1s - loss: 0.0045 - accuracy: 1.00 - ETA: 1s - loss: 0.0045 - accuracy: 1.00 - ETA: 1s - loss: 0.0045 - accuracy: 1.00 - ETA: 0s - loss: 0.0046 - accuracy: 1.00 - ETA: 0s - loss: 0.0046 - accuracy: 1.00 - ETA: 0s - loss: 0.0045 - accuracy: 1.00 - ETA: 0s - loss: 0.0045 - accuracy: 1.00 - ETA: 0s - loss: 0.0044 - accuracy: 1.00 - 18s 281ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 3.3646 - val_accuracy: 0.5000\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - ETA: 20s - loss: 0.0019 - accuracy: 1.000 - ETA: 13s - loss: 0.0042 - accuracy: 1.000 - ETA: 12s - loss: 0.0036 - accuracy: 1.000 - ETA: 12s - loss: 0.0036 - accuracy: 1.000 - ETA: 11s - loss: 0.0037 - accuracy: 1.000 - ETA: 11s - loss: 0.0033 - accuracy: 1.000 - ETA: 11s - loss: 0.0031 - accuracy: 1.000 - ETA: 11s - loss: 0.0029 - accuracy: 1.000 - ETA: 11s - loss: 0.0029 - accuracy: 1.000 - ETA: 10s - loss: 0.0029 - accuracy: 1.000 - ETA: 10s - loss: 0.0031 - accuracy: 1.000 - ETA: 10s - loss: 0.0029 - accuracy: 1.000 - ETA: 10s - loss: 0.0031 - accuracy: 1.000 - ETA: 9s - loss: 0.0030 - accuracy: 1.000 - ETA: 9s - loss: 0.0031 - accuracy: 1.00 - ETA: 9s - loss: 0.0030 - accuracy: 1.00 - ETA: 9s - loss: 0.0030 - accuracy: 1.00 - ETA: 9s - loss: 0.0029 - accuracy: 1.00 - ETA: 8s - loss: 0.0029 - accuracy: 1.00 - ETA: 8s - loss: 0.0029 - accuracy: 1.00 - ETA: 8s - loss: 0.0032 - accuracy: 1.00 - ETA: 8s - loss: 0.0031 - accuracy: 1.00 - ETA: 7s - loss: 0.0034 - accuracy: 1.00 - ETA: 7s - loss: 0.0034 - accuracy: 1.00 - ETA: 7s - loss: 0.0033 - accuracy: 1.00 - ETA: 7s - loss: 0.0034 - accuracy: 1.00 - ETA: 7s - loss: 0.0034 - accuracy: 1.00 - ETA: 7s - loss: 0.0034 - accuracy: 1.00 - ETA: 6s - loss: 0.0033 - accuracy: 1.00 - ETA: 6s - loss: 0.0032 - accuracy: 1.00 - ETA: 6s - loss: 0.0032 - accuracy: 1.00 - ETA: 6s - loss: 0.0031 - accuracy: 1.00 - ETA: 6s - loss: 0.0031 - accuracy: 1.00 - ETA: 5s - loss: 0.0031 - accuracy: 1.00 - ETA: 5s - loss: 0.0030 - accuracy: 1.00 - ETA: 5s - loss: 0.0031 - accuracy: 1.00 - ETA: 5s - loss: 0.0032 - accuracy: 1.00 - ETA: 5s - loss: 0.0033 - accuracy: 1.00 - ETA: 4s - loss: 0.0034 - accuracy: 1.00 - ETA: 4s - loss: 0.0033 - accuracy: 1.00 - ETA: 4s - loss: 0.0033 - accuracy: 1.00 - ETA: 4s - loss: 0.0034 - accuracy: 1.00 - ETA: 4s - loss: 0.0034 - accuracy: 1.00 - ETA: 3s - loss: 0.0034 - accuracy: 1.00 - ETA: 3s - loss: 0.0034 - accuracy: 1.00 - ETA: 3s - loss: 0.0033 - accuracy: 1.00 - ETA: 3s - loss: 0.0034 - accuracy: 1.00 - ETA: 3s - loss: 0.0034 - accuracy: 1.00 - ETA: 2s - loss: 0.0034 - accuracy: 1.00 - ETA: 2s - loss: 0.0035 - accuracy: 1.00 - ETA: 2s - loss: 0.0035 - accuracy: 1.00 - ETA: 2s - loss: 0.0035 - accuracy: 1.00 - ETA: 2s - loss: 0.0036 - accuracy: 1.00 - ETA: 1s - loss: 0.0036 - accuracy: 1.00 - ETA: 1s - loss: 0.0036 - accuracy: 1.00 - ETA: 1s - loss: 0.0036 - accuracy: 1.00 - ETA: 1s - loss: 0.0036 - accuracy: 1.00 - ETA: 0s - loss: 0.0036 - accuracy: 1.00 - ETA: 0s - loss: 0.0036 - accuracy: 1.00 - ETA: 0s - loss: 0.0035 - accuracy: 1.00 - ETA: 0s - loss: 0.0036 - accuracy: 1.00 - ETA: 0s - loss: 0.0036 - accuracy: 1.00 - 18s 288ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 3.5320 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a352a15a88>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_generator, epochs=5, validation_data=validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate_generator(validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 3.5320415645837784, Accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "print('Loss: {}, Accuracy: {}'.format(loss, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
